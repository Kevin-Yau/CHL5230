{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Kevin-Yau/CHL5230/blob/main/Datathon_4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vaan5YWBsD6m"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "-tfwyeFs7ncq"
      },
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "L9nJymvq78Cq"
      },
      "outputs": [],
      "source": [
        "# Read the dataset into a Pandas DataFrame\n",
        "df = pd.read_csv('datathon4.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8lqCPg407reO",
        "outputId": "e27e1dfc-ba27-4879-f653-e6aa9e495ec3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(91713, 186)\n",
            "Index(['encounter_id', 'patient_id', 'hospital_id', 'hospital_death', 'age',\n",
            "       'bmi', 'elective_surgery', 'ethnicity', 'gender', 'height',\n",
            "       ...\n",
            "       'aids', 'cirrhosis', 'diabetes_mellitus', 'hepatic_failure',\n",
            "       'immunosuppression', 'leukemia', 'lymphoma',\n",
            "       'solid_tumor_with_metastasis', 'apache_3j_bodysystem',\n",
            "       'apache_2_bodysystem'],\n",
            "      dtype='object', length=186)\n"
          ]
        }
      ],
      "source": [
        "# read dataset\n",
        "ICU_df = pd.read_csv('datathon4.csv')\n",
        "ICU_df.head()\n",
        "\n",
        "# check dimension of the dataset\n",
        "print(ICU_df.shape)\n",
        "\n",
        "# list the columns of the dataframe\n",
        "print(ICU_df.columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "id": "9XRdvZMx-EI8",
        "outputId": "7ed2bbec-d5d2-4afb-85b9-12c9cef30dba"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   encounter_id  patient_id  hospital_id  hospital_death   age    bmi  \\\n",
              "0         66154       25312          118               0  68.0  22.73   \n",
              "1        114252       59342           81               0  77.0  27.42   \n",
              "2        119783       50777          118               0  25.0  31.95   \n",
              "3         79267       46918          118               0  81.0  22.64   \n",
              "4         92056       34377           33               0  19.0    NaN   \n",
              "\n",
              "   elective_surgery  ethnicity gender  height  ... aids cirrhosis  \\\n",
              "0                 0  Caucasian      M   180.3  ...  0.0       0.0   \n",
              "1                 0  Caucasian      F   160.0  ...  0.0       0.0   \n",
              "2                 0  Caucasian      F   172.7  ...  0.0       0.0   \n",
              "3                 1  Caucasian      F   165.1  ...  0.0       0.0   \n",
              "4                 0  Caucasian      M   188.0  ...  0.0       0.0   \n",
              "\n",
              "   diabetes_mellitus hepatic_failure immunosuppression  leukemia  lymphoma  \\\n",
              "0                1.0             0.0               0.0       0.0       0.0   \n",
              "1                1.0             0.0               0.0       0.0       0.0   \n",
              "2                0.0             0.0               0.0       0.0       0.0   \n",
              "3                0.0             0.0               0.0       0.0       0.0   \n",
              "4                0.0             0.0               0.0       0.0       0.0   \n",
              "\n",
              "   solid_tumor_with_metastasis  apache_3j_bodysystem  apache_2_bodysystem  \n",
              "0                          0.0                Sepsis       Cardiovascular  \n",
              "1                          0.0           Respiratory          Respiratory  \n",
              "2                          0.0             Metabolic            Metabolic  \n",
              "3                          0.0        Cardiovascular       Cardiovascular  \n",
              "4                          0.0                Trauma               Trauma  \n",
              "\n",
              "[5 rows x 186 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8c00ecec-0154-4268-aa75-5d85a719b9ff\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>encounter_id</th>\n",
              "      <th>patient_id</th>\n",
              "      <th>hospital_id</th>\n",
              "      <th>hospital_death</th>\n",
              "      <th>age</th>\n",
              "      <th>bmi</th>\n",
              "      <th>elective_surgery</th>\n",
              "      <th>ethnicity</th>\n",
              "      <th>gender</th>\n",
              "      <th>height</th>\n",
              "      <th>...</th>\n",
              "      <th>aids</th>\n",
              "      <th>cirrhosis</th>\n",
              "      <th>diabetes_mellitus</th>\n",
              "      <th>hepatic_failure</th>\n",
              "      <th>immunosuppression</th>\n",
              "      <th>leukemia</th>\n",
              "      <th>lymphoma</th>\n",
              "      <th>solid_tumor_with_metastasis</th>\n",
              "      <th>apache_3j_bodysystem</th>\n",
              "      <th>apache_2_bodysystem</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>66154</td>\n",
              "      <td>25312</td>\n",
              "      <td>118</td>\n",
              "      <td>0</td>\n",
              "      <td>68.0</td>\n",
              "      <td>22.73</td>\n",
              "      <td>0</td>\n",
              "      <td>Caucasian</td>\n",
              "      <td>M</td>\n",
              "      <td>180.3</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Sepsis</td>\n",
              "      <td>Cardiovascular</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>114252</td>\n",
              "      <td>59342</td>\n",
              "      <td>81</td>\n",
              "      <td>0</td>\n",
              "      <td>77.0</td>\n",
              "      <td>27.42</td>\n",
              "      <td>0</td>\n",
              "      <td>Caucasian</td>\n",
              "      <td>F</td>\n",
              "      <td>160.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Respiratory</td>\n",
              "      <td>Respiratory</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>119783</td>\n",
              "      <td>50777</td>\n",
              "      <td>118</td>\n",
              "      <td>0</td>\n",
              "      <td>25.0</td>\n",
              "      <td>31.95</td>\n",
              "      <td>0</td>\n",
              "      <td>Caucasian</td>\n",
              "      <td>F</td>\n",
              "      <td>172.7</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Metabolic</td>\n",
              "      <td>Metabolic</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>79267</td>\n",
              "      <td>46918</td>\n",
              "      <td>118</td>\n",
              "      <td>0</td>\n",
              "      <td>81.0</td>\n",
              "      <td>22.64</td>\n",
              "      <td>1</td>\n",
              "      <td>Caucasian</td>\n",
              "      <td>F</td>\n",
              "      <td>165.1</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Cardiovascular</td>\n",
              "      <td>Cardiovascular</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>92056</td>\n",
              "      <td>34377</td>\n",
              "      <td>33</td>\n",
              "      <td>0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>Caucasian</td>\n",
              "      <td>M</td>\n",
              "      <td>188.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Trauma</td>\n",
              "      <td>Trauma</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 186 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8c00ecec-0154-4268-aa75-5d85a719b9ff')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-8c00ecec-0154-4268-aa75-5d85a719b9ff button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-8c00ecec-0154-4268-aa75-5d85a719b9ff');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-1ddd0131-8676-4ce2-9113-6075837be9e9\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-1ddd0131-8676-4ce2-9113-6075837be9e9')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-1ddd0131-8676-4ce2-9113-6075837be9e9 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v7ur8g7uBBOc",
        "outputId": "43928090-5339-4bf3-b185-5a4d908c82c1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "        encounter_id     patient_id   hospital_id  hospital_death  \\\n",
            "count   91713.000000   91713.000000  91713.000000    91713.000000   \n",
            "mean    65606.079280   65537.131464    105.669262        0.086302   \n",
            "std     37795.088538   37811.252183     62.854406        0.280811   \n",
            "min         1.000000       1.000000      2.000000        0.000000   \n",
            "25%     32852.000000   32830.000000     47.000000        0.000000   \n",
            "50%     65665.000000   65413.000000    109.000000        0.000000   \n",
            "75%     98342.000000   98298.000000    161.000000        0.000000   \n",
            "max    131051.000000  131051.000000    204.000000        1.000000   \n",
            "\n",
            "                age           bmi  elective_surgery        height  \\\n",
            "count  87485.000000  88284.000000      91713.000000  90379.000000   \n",
            "mean      62.309516     29.185818          0.183736    169.641588   \n",
            "std       16.775119      8.275142          0.387271     10.795378   \n",
            "min       16.000000     14.844926          0.000000    137.200000   \n",
            "25%       52.000000     23.641975          0.000000    162.500000   \n",
            "50%       65.000000     27.654655          0.000000    170.100000   \n",
            "75%       75.000000     32.930206          0.000000    177.800000   \n",
            "max       89.000000     67.814990          1.000000    195.590000   \n",
            "\n",
            "             icu_id  pre_icu_los_days  ...  apache_4a_hospital_death_prob  \\\n",
            "count  91713.000000      91713.000000  ...                   83766.000000   \n",
            "mean     508.357692          0.835766  ...                       0.086787   \n",
            "std      228.989661          2.487756  ...                       0.247569   \n",
            "min       82.000000        -24.947222  ...                      -1.000000   \n",
            "25%      369.000000          0.035417  ...                       0.020000   \n",
            "50%      504.000000          0.138889  ...                       0.050000   \n",
            "75%      679.000000          0.409028  ...                       0.130000   \n",
            "max      927.000000        159.090972  ...                       0.990000   \n",
            "\n",
            "       apache_4a_icu_death_prob          aids     cirrhosis  \\\n",
            "count              83766.000000  90998.000000  90998.000000   \n",
            "mean                   0.043955      0.000857      0.015693   \n",
            "std                    0.217341      0.029265      0.124284   \n",
            "min                   -1.000000      0.000000      0.000000   \n",
            "25%                    0.010000      0.000000      0.000000   \n",
            "50%                    0.020000      0.000000      0.000000   \n",
            "75%                    0.060000      0.000000      0.000000   \n",
            "max                    0.970000      1.000000      1.000000   \n",
            "\n",
            "       diabetes_mellitus  hepatic_failure  immunosuppression      leukemia  \\\n",
            "count       90998.000000     90998.000000       90998.000000  90998.000000   \n",
            "mean            0.225192         0.012989           0.026165      0.007066   \n",
            "std             0.417711         0.113229           0.159628      0.083763   \n",
            "min             0.000000         0.000000           0.000000      0.000000   \n",
            "25%             0.000000         0.000000           0.000000      0.000000   \n",
            "50%             0.000000         0.000000           0.000000      0.000000   \n",
            "75%             0.000000         0.000000           0.000000      0.000000   \n",
            "max             1.000000         1.000000           1.000000      1.000000   \n",
            "\n",
            "           lymphoma  solid_tumor_with_metastasis  \n",
            "count  90998.000000                 90998.000000  \n",
            "mean       0.004132                     0.020638  \n",
            "std        0.064148                     0.142169  \n",
            "min        0.000000                     0.000000  \n",
            "25%        0.000000                     0.000000  \n",
            "50%        0.000000                     0.000000  \n",
            "75%        0.000000                     0.000000  \n",
            "max        1.000000                     1.000000  \n",
            "\n",
            "[8 rows x 178 columns]\n"
          ]
        }
      ],
      "source": [
        "# Display summary statistics\n",
        "print(df.describe())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_EJh5sUUlsb7",
        "outputId": "04f8d4a4-dde8-4ae7-e463-4eb0c08e3cba"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "count    90835.000000\n",
              "mean        99.707932\n",
              "std         30.870502\n",
              "min         30.000000\n",
              "25%         86.000000\n",
              "50%        104.000000\n",
              "75%        120.000000\n",
              "max        178.000000\n",
              "Name: heart_rate_apache, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "# Display summary statistics\n",
        "df['heart_rate_apache'].describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 320
        },
        "id": "_SH_16b8youe",
        "outputId": "5489e146-36e7-445c-b3c8-34037af2ccef"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "             weight  readmission_status  albumin_apache  apache_2_diagnosis  \\\n",
              "count  88993.000000             91713.0    37334.000000        90051.000000   \n",
              "mean      84.028340                 0.0        2.902968          185.401739   \n",
              "std       25.011497                 0.0        0.681863           86.050882   \n",
              "min       38.600000                 0.0        1.200000          101.000000   \n",
              "25%       66.800000                 0.0        2.400000          113.000000   \n",
              "50%       80.300000                 0.0        2.900000          122.000000   \n",
              "75%       97.100000                 0.0        3.400000          301.000000   \n",
              "max      186.000000                 0.0        4.600000          308.000000   \n",
              "\n",
              "       apache_3j_diagnosis  apache_post_operative    arf_apache  \\\n",
              "count         90612.000000           91713.000000  90998.000000   \n",
              "mean            558.216377               0.201106      0.027979   \n",
              "std             463.266985               0.400829      0.164912   \n",
              "min               0.010000               0.000000      0.000000   \n",
              "25%             203.010000               0.000000      0.000000   \n",
              "50%             409.020000               0.000000      0.000000   \n",
              "75%             703.030000               0.000000      0.000000   \n",
              "max            2201.050000               1.000000      1.000000   \n",
              "\n",
              "       bilirubin_apache   bun_apache  creatinine_apache   fio2_apache  \\\n",
              "count      33579.000000  72451.00000       72860.000000  20845.000000   \n",
              "mean           1.147721     25.82533           1.480014      0.595751   \n",
              "std            2.165538     20.67298           1.525787      0.263238   \n",
              "min            0.100000      4.00000           0.300000      0.210000   \n",
              "25%            0.400000     13.00000           0.720000      0.400000   \n",
              "50%            0.600000     19.00000           0.980000      0.500000   \n",
              "75%            1.100000     32.00000           1.530000      0.850000   \n",
              "max           51.000000    127.00000          11.180000      1.000000   \n",
              "\n",
              "       gcs_eyes_apache  gcs_motor_apache  gcs_unable_apache  gcs_verbal_apache  \n",
              "count     89812.000000      89812.000000       90676.000000       89812.000000  \n",
              "mean          3.465049          5.471195           0.009528           3.994778  \n",
              "std           0.951715          1.288376           0.097148           1.560166  \n",
              "min           1.000000          1.000000           0.000000           1.000000  \n",
              "25%           3.000000          6.000000           0.000000           4.000000  \n",
              "50%           4.000000          6.000000           0.000000           5.000000  \n",
              "75%           4.000000          6.000000           0.000000           5.000000  \n",
              "max           4.000000          6.000000           1.000000           5.000000  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e3d2e533-ed87-4405-8b85-b8e5f59f30d7\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>weight</th>\n",
              "      <th>readmission_status</th>\n",
              "      <th>albumin_apache</th>\n",
              "      <th>apache_2_diagnosis</th>\n",
              "      <th>apache_3j_diagnosis</th>\n",
              "      <th>apache_post_operative</th>\n",
              "      <th>arf_apache</th>\n",
              "      <th>bilirubin_apache</th>\n",
              "      <th>bun_apache</th>\n",
              "      <th>creatinine_apache</th>\n",
              "      <th>fio2_apache</th>\n",
              "      <th>gcs_eyes_apache</th>\n",
              "      <th>gcs_motor_apache</th>\n",
              "      <th>gcs_unable_apache</th>\n",
              "      <th>gcs_verbal_apache</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>88993.000000</td>\n",
              "      <td>91713.0</td>\n",
              "      <td>37334.000000</td>\n",
              "      <td>90051.000000</td>\n",
              "      <td>90612.000000</td>\n",
              "      <td>91713.000000</td>\n",
              "      <td>90998.000000</td>\n",
              "      <td>33579.000000</td>\n",
              "      <td>72451.00000</td>\n",
              "      <td>72860.000000</td>\n",
              "      <td>20845.000000</td>\n",
              "      <td>89812.000000</td>\n",
              "      <td>89812.000000</td>\n",
              "      <td>90676.000000</td>\n",
              "      <td>89812.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>84.028340</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.902968</td>\n",
              "      <td>185.401739</td>\n",
              "      <td>558.216377</td>\n",
              "      <td>0.201106</td>\n",
              "      <td>0.027979</td>\n",
              "      <td>1.147721</td>\n",
              "      <td>25.82533</td>\n",
              "      <td>1.480014</td>\n",
              "      <td>0.595751</td>\n",
              "      <td>3.465049</td>\n",
              "      <td>5.471195</td>\n",
              "      <td>0.009528</td>\n",
              "      <td>3.994778</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>25.011497</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.681863</td>\n",
              "      <td>86.050882</td>\n",
              "      <td>463.266985</td>\n",
              "      <td>0.400829</td>\n",
              "      <td>0.164912</td>\n",
              "      <td>2.165538</td>\n",
              "      <td>20.67298</td>\n",
              "      <td>1.525787</td>\n",
              "      <td>0.263238</td>\n",
              "      <td>0.951715</td>\n",
              "      <td>1.288376</td>\n",
              "      <td>0.097148</td>\n",
              "      <td>1.560166</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>38.600000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.200000</td>\n",
              "      <td>101.000000</td>\n",
              "      <td>0.010000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>4.00000</td>\n",
              "      <td>0.300000</td>\n",
              "      <td>0.210000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>66.800000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.400000</td>\n",
              "      <td>113.000000</td>\n",
              "      <td>203.010000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.400000</td>\n",
              "      <td>13.00000</td>\n",
              "      <td>0.720000</td>\n",
              "      <td>0.400000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>4.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>80.300000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.900000</td>\n",
              "      <td>122.000000</td>\n",
              "      <td>409.020000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.600000</td>\n",
              "      <td>19.00000</td>\n",
              "      <td>0.980000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>5.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>97.100000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.400000</td>\n",
              "      <td>301.000000</td>\n",
              "      <td>703.030000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.100000</td>\n",
              "      <td>32.00000</td>\n",
              "      <td>1.530000</td>\n",
              "      <td>0.850000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>5.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>186.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.600000</td>\n",
              "      <td>308.000000</td>\n",
              "      <td>2201.050000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>51.000000</td>\n",
              "      <td>127.00000</td>\n",
              "      <td>11.180000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>5.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e3d2e533-ed87-4405-8b85-b8e5f59f30d7')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-e3d2e533-ed87-4405-8b85-b8e5f59f30d7 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-e3d2e533-ed87-4405-8b85-b8e5f59f30d7');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-d727c1d1-c0ac-4118-8c33-d2c760f054a8\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-d727c1d1-c0ac-4118-8c33-d2c760f054a8')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-d727c1d1-c0ac-4118-8c33-d2c760f054a8 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "# Display summary statistics\n",
        "df[['weight','readmission_status','albumin_apache','apache_2_diagnosis','apache_3j_diagnosis','apache_post_operative','arf_apache','bilirubin_apache','bun_apache','creatinine_apache','fio2_apache','gcs_eyes_apache','gcs_motor_apache','gcs_unable_apache','gcs_verbal_apache']].describe()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b1ugoulCBQNz",
        "outputId": "4d36549a-d7ca-4ef6-fcb2-7a3806c18542"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "encounter_id                      0\n",
            "patient_id                        0\n",
            "hospital_id                       0\n",
            "hospital_death                    0\n",
            "age                            4228\n",
            "                               ... \n",
            "leukemia                        715\n",
            "lymphoma                        715\n",
            "solid_tumor_with_metastasis     715\n",
            "apache_3j_bodysystem           1662\n",
            "apache_2_bodysystem            1662\n",
            "Length: 186, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# check missing value\n",
        "print(ICU_df.isnull().sum())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "15p4wq3rDcuO"
      },
      "outputs": [],
      "source": [
        "# importing PyTorch library as 't' for convenience\n",
        "import torch as t\n",
        "\n",
        "# importing other necessary libraries\n",
        "import numpy as np\n",
        "from torch.nn.functional import sigmoid, relu, tanh\n",
        "from torch.optim import Adam\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "\n",
        "# importing PyTorch modules for building neural networks\n",
        "from torch.nn import Tanh, Linear, Sequential, Sigmoid, Dropout\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "iAREVr3UDhUg"
      },
      "outputs": [],
      "source": [
        "# Defining the input to the neuron - a single example with 3 features\n",
        "X = np.array([\n",
        "    [0, 1, 2]\n",
        "])\n",
        "\n",
        "# Defining the expected output for the given input\n",
        "Y = np.array([\n",
        "    [1]\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-FnaUEBiDpWN",
        "outputId": "d69107e0-36cc-41c3-da93-eee26fa42426"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[ 0.8082],\n",
            "        [-1.0046],\n",
            "        [-0.1345]])\n",
            "torch.float32\n",
            "torch.Size([3, 1])\n",
            "===========\n",
            "tensor([[0.]])\n",
            "torch.float32\n",
            "torch.Size([1, 1])\n"
          ]
        }
      ],
      "source": [
        "# Initializing the weights randomly for 3 inputs and 1 output\n",
        "W = t.randn((3,1))\n",
        "print(W)\n",
        "print(W.dtype) # Checking the data type of the weights tensor\n",
        "print(W.shape) # Checking the shape of the weights tensor\n",
        "print('===========')\n",
        "\n",
        "# Initializing the bias as a tensor with a single zero element\n",
        "B = t.zeros((1,1))\n",
        "print(B)\n",
        "print(B.dtype) # Checking the data type of the bias tensor\n",
        "print(B.shape) # Checking the shape of the bias tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1_BI5ZlgDujN",
        "outputId": "e5068425-3981-4ae6-eb6c-a904fc26bd17"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[-1.2736]])\n",
            "tensor([[-1.2736]])\n"
          ]
        }
      ],
      "source": [
        "# Converting the input array to a PyTorch Tensor and performing matrix multiplication with the weights\n",
        "XW = t.Tensor(X) @ W\n",
        "print(XW)\n",
        "\n",
        "# Adding the bias to the result of the matrix multiplication\n",
        "XW_B = XW + B\n",
        "print(XW_B)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6DL5gcU2Dxbi",
        "outputId": "a935713f-fb81-412e-c40a-6c3d5ce4d50c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[-0.8548]])\n"
          ]
        }
      ],
      "source": [
        "# Applying the hyperbolic tangent activation function element-wise to the result\n",
        "output = tanh(XW_B)\n",
        "print(output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J1DCOUIjD0hY",
        "outputId": "630e7611-b3b2-4c6e-abbd-56cf14b42094"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(3.4402)\n"
          ]
        }
      ],
      "source": [
        "# Calculating the Mean Squared Error (MSE) loss between the predicted output and the actual output\n",
        "loss = t.nn.functional.mse_loss(output, t.Tensor(Y))\n",
        "print(loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vuqNfpr4D-OJ",
        "outputId": "ae2085a1-682b-4a25-d531-c3a96050d143"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[1.],\n",
            "        [1.]], grad_fn=<SigmoidBackward0>)\n"
          ]
        }
      ],
      "source": [
        "# Defining multiple inputs for batch processing\n",
        "X = t.Tensor([\n",
        "    # A batch of examples with 3 features each\n",
        "    [0, 5, 2],\n",
        "    [0, 3, 4],\n",
        "    # ...\n",
        "]).type(t.float32)\n",
        "\n",
        "# Defining the expected outputs for the batch of inputs (for a binary classification problem)\n",
        "Y = t.Tensor([\n",
        "    # Corresponding expected outputs (labels)\n",
        "    [1],\n",
        "    [1],\n",
        "    # ...\n",
        "]).type(t.float32)\n",
        "\n",
        "# Initializing weights and bias with the requirement to compute gradients (for learning during training)\n",
        "W = t.randn((3,1), requires_grad=True)\n",
        "B = t.zeros((1,1), requires_grad=True).type(t.float32)\n",
        "\n",
        "# Defining the loss function for binary classification (Binary Cross-Entropy Loss)\n",
        "loss_fn = t.nn.BCELoss()\n",
        "\n",
        "# Setting up the optimizer (Adam) with the parameters to optimize (weights and bias) and the learning rate\n",
        "learning_rate = 1\n",
        "optimizer = Adam([W, B], lr=learning_rate)\n",
        "\n",
        "# Defining the number of iterations for training and a list to keep track of loss values\n",
        "number_of_iterations = 100\n",
        "loss_list = []\n",
        "for _ in range(number_of_iterations):\n",
        "\n",
        "    # Forward pass: computing the predicted output using the sigmoid activation function\n",
        "    out = sigmoid(X @ W  + B)\n",
        "\n",
        "    # Calculating the loss\n",
        "    loss = loss_fn(out.view(-1), Y.view(-1))\n",
        "\n",
        "    # Recording the loss value for visualization\n",
        "    loss_list.append(loss.item())\n",
        "\n",
        "    # Clearing previous gradients before the backward pass\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # Backward pass: computing gradients\n",
        "    loss.backward()\n",
        "\n",
        "    # Updating the weights and bias based on the gradients computed\n",
        "    optimizer.step()\n",
        "\n",
        "# Printing the probabilities predicted by the neuron for each input\n",
        "print(sigmoid(X @ W  + B))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "_ggipBVdED8i",
        "outputId": "046bab29-4fff-4cd8-877a-13efbb52a0de"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Plotting the loss values recorded during training\n",
        "plt.plot([i for i in range(len(loss_list))], loss_list)\n",
        "plt.xlabel('Iteration')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Loss Over Iterations')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Doxl6QXLEIiH",
        "outputId": "ef8ea396-b693-427c-c10b-86e8adbb753c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.1.0+cu118)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install torch\n",
        "\n",
        "# importing torch as t\n",
        "import torch as t\n",
        "import numpy as np\n",
        "from torch.nn.functional import sigmoid, relu, tanh\n",
        "from torch.optim import Adam\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "\n",
        "from torch.nn import Tanh, Linear, Sequential, Sigmoid, Dropout"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "limGAbT1EZMi",
        "outputId": "2e76a313-5102-4428-f01f-a20f1c845bf5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "encounter_id                     int64\n",
              "patient_id                       int64\n",
              "hospital_id                      int64\n",
              "hospital_death                   int64\n",
              "age                            float64\n",
              "                                ...   \n",
              "leukemia                       float64\n",
              "lymphoma                       float64\n",
              "solid_tumor_with_metastasis    float64\n",
              "apache_3j_bodysystem            object\n",
              "apache_2_bodysystem             object\n",
              "Length: 186, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "# checking the data types\n",
        "ICU_df.dtypes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BhjDQrO5Ensk",
        "outputId": "07d8c202-83d2-4718-beea-5338c81a2e76"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['encounter_id', 'patient_id', 'hospital_id', 'hospital_death', 'age',\n",
              "       'bmi', 'elective_surgery', 'ethnicity', 'gender', 'height',\n",
              "       ...\n",
              "       'aids', 'cirrhosis', 'diabetes_mellitus', 'hepatic_failure',\n",
              "       'immunosuppression', 'leukemia', 'lymphoma',\n",
              "       'solid_tumor_with_metastasis', 'apache_3j_bodysystem',\n",
              "       'apache_2_bodysystem'],\n",
              "      dtype='object', length=186)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "ICU_df.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o--tPziEEzuu",
        "outputId": "44105962-d88c-4cc4-9f39-c7f191322b57"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.08630183289173836"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "ICU_df['hospital_death'].mean()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bphGlp3aTA-p",
        "outputId": "2eac99a8-0b8c-4184-afcd-82ada2a9ff9f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Caucasian' nan 'Hispanic' 'African American' 'Asian' 'Native American'\n",
            " 'Other/Unknown']\n"
          ]
        }
      ],
      "source": [
        "# Display unique values in 'ethnicity' column\n",
        "print(ICU_df['ethnicity'].unique())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "PpbgVNZ5jIOP"
      },
      "outputs": [],
      "source": [
        "#Drop Encounter ID\n",
        "ICU_df= ICU_df.drop('encounter_id', axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ac_cY3XoU1fs",
        "outputId": "f5dc2c3f-39f3-4bb8-ab17-c10e5c89c8ab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Floor' 'Accident & Emergency' 'Operating Room / Recovery'\n",
            " 'Other Hospital' 'Other ICU' nan]\n"
          ]
        }
      ],
      "source": [
        "# Display unique values in 'icu_admit_source' column\n",
        "print(ICU_df['icu_admit_source'].unique())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "oaJZI6YoXL_F"
      },
      "outputs": [],
      "source": [
        "ICU_df['gender'].replace({'F' : 1, 'M' : 0}, inplace=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-HuJJc_RlnMP",
        "outputId": "ce1a29ba-9b23-41d0-f0d8-72ead08b2d3d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 0.  1. nan]\n"
          ]
        }
      ],
      "source": [
        "#Display Gender\n",
        "print(ICU_df['gender'].unique())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zpWqBPWzmLHB",
        "outputId": "e9bfeeea-654d-46a4-d926-8d300a0175e1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   patient_id  hospital_id  hospital_death   age    bmi  elective_surgery  \\\n",
            "0       25312          118               0  68.0  22.73                 0   \n",
            "1       59342           81               0  77.0  27.42                 0   \n",
            "2       50777          118               0  25.0  31.95                 0   \n",
            "3       46918          118               0  81.0  22.64                 1   \n",
            "4       34377           33               0  19.0    NaN                 0   \n",
            "\n",
            "   gender  height  icu_id  pre_icu_los_days  ...  \\\n",
            "0     0.0   180.3      92          0.541667  ...   \n",
            "1     1.0   160.0      90          0.927778  ...   \n",
            "2     1.0   172.7      93          0.000694  ...   \n",
            "3     1.0   165.1      92          0.000694  ...   \n",
            "4     0.0   188.0      91          0.073611  ...   \n",
            "\n",
            "   apache_4a_hospital_death_prob  apache_4a_icu_death_prob  aids  cirrhosis  \\\n",
            "0                           0.10                      0.05   0.0        0.0   \n",
            "1                           0.47                      0.29   0.0        0.0   \n",
            "2                           0.00                      0.00   0.0        0.0   \n",
            "3                           0.04                      0.03   0.0        0.0   \n",
            "4                            NaN                       NaN   0.0        0.0   \n",
            "\n",
            "   diabetes_mellitus  hepatic_failure  immunosuppression  leukemia  lymphoma  \\\n",
            "0                1.0              0.0                0.0       0.0       0.0   \n",
            "1                1.0              0.0                0.0       0.0       0.0   \n",
            "2                0.0              0.0                0.0       0.0       0.0   \n",
            "3                0.0              0.0                0.0       0.0       0.0   \n",
            "4                0.0              0.0                0.0       0.0       0.0   \n",
            "\n",
            "   solid_tumor_with_metastasis  \n",
            "0                          0.0  \n",
            "1                          0.0  \n",
            "2                          0.0  \n",
            "3                          0.0  \n",
            "4                          0.0  \n",
            "\n",
            "[5 rows x 178 columns]\n"
          ]
        }
      ],
      "source": [
        "# List of columns to drop due to categorical problems\n",
        "columns_to_drop = ['ethnicity', 'icu_admit_source','hospital_admit_source', 'icu_stay_type', 'icu_type', 'apache_3j_bodysystem', 'apache_2_bodysystem']\n",
        "\n",
        "# Dropping the specified columns from the DataFrame\n",
        "ICU_df.drop(columns_to_drop, axis=1, inplace=True)\n",
        "\n",
        "# Verify the updated DataFrame\n",
        "print(ICU_df.head())  # You can use head() to verify the updated DataFrame"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a_sgAQeDMUgu",
        "outputId": "af9e0790-afee-4ab8-9c76-a1ac8c1583bc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting category_encoders\n",
            "  Downloading category_encoders-2.6.3-py2.py3-none-any.whl (81 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m81.9/81.9 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from category_encoders) (1.23.5)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from category_encoders) (1.2.2)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from category_encoders) (1.11.3)\n",
            "Requirement already satisfied: statsmodels>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from category_encoders) (0.14.0)\n",
            "Requirement already satisfied: pandas>=1.0.5 in /usr/local/lib/python3.10/dist-packages (from category_encoders) (1.5.3)\n",
            "Requirement already satisfied: patsy>=0.5.1 in /usr/local/lib/python3.10/dist-packages (from category_encoders) (0.5.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.5->category_encoders) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.5->category_encoders) (2023.3.post1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from patsy>=0.5.1->category_encoders) (1.16.0)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->category_encoders) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->category_encoders) (3.2.0)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.10/dist-packages (from statsmodels>=0.9.0->category_encoders) (23.2)\n",
            "Installing collected packages: category_encoders\n",
            "Successfully installed category_encoders-2.6.3\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "!pip install category_encoders\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import warnings\n",
        "from sklearn import tree\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import seaborn as sns\n",
        "import scipy.stats as stats\n",
        "import matplotlib.pyplot as plt\n",
        "# from sklearn.metrics import RocCurveDisplay, auc, roc_curve\n",
        "from sklearn.metrics import roc_auc_score, accuracy_score\n",
        "import plotly.express as px\n",
        "from category_encoders import OneHotEncoder, TargetEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import RandomizedSearchCV, StratifiedKFold\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "\n",
        "from sklearn import tree\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import seaborn as sns\n",
        "import scipy.stats as stats\n",
        "import matplotlib.pyplot as plt\n",
        "# from sklearn.metrics import RocCurveDisplay, auc, roc_curve\n",
        "from sklearn.metrics import roc_auc_score, accuracy_score\n",
        "import plotly.express as px\n",
        "from category_encoders import OneHotEncoder, TargetEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import RandomizedSearchCV, StratifiedKFold\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vpl9jPNeQnXS",
        "outputId": "b1487263-a192-479d-c556-b8e8bd889bdd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array(['Floor', 'Accident & Emergency', 'Operating Room / Recovery',\n",
              "       'Other Hospital', 'Other ICU', nan], dtype=object)"
            ]
          },
          "execution_count": 154,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# List of columns that contain categorical data\n",
        "target_column = 'hospital_death'\n",
        "categorical_columns = ['ethnicity','icu_admit_source','icu_stay_type','icu_type','apache_3j_bodysystem','apache_2_bodysystem']\n",
        "\n",
        "# List of columns that contain numerical data (excluding categorical columns and the target column)\n",
        "numerical_columns = [c for c in ICU_df.columns if c not in categorical_columns and c != target_column]\n",
        "columns = numerical_columns + categorical_columns\n",
        "\n",
        "# Display the unique values in the 'icu_admit_source' column\n",
        "ICU_df['icu_admit_source'].unique()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 513
        },
        "id": "T9NGtV29O18C",
        "outputId": "f3403206-d086-4d0a-998c-eb3d021feecd"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3801\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3802\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3803\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'icu_type'",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-109-7e8223c2b959>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mICU_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'icu_type'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3805\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3806\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3807\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3808\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3809\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3802\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3803\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3804\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3805\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3806\u001b[0m                 \u001b[0;31m# If we have a listlike key, _check_indexing_error will raise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'icu_type'"
          ]
        }
      ],
      "source": [
        "ICU_df['icu_type'].unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vx_DnMxfYNvO",
        "outputId": "af7d89d3-596f-4692-af33-ef2530e8c833"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array(['Floor', 'Accident & Emergency', 'Operating Room / Recovery',\n",
              "       'Other Hospital', 'Other ICU', nan], dtype=object)"
            ]
          },
          "execution_count": 166,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "ICU_df['icu_admit_source'].unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m2rGQNvHQ8-i"
      },
      "outputs": [],
      "source": [
        "# Randomly sample 70% of the data for training\n",
        "train_data = ICU_df.sample(frac = .7, random_state=10)\n",
        "\n",
        "# Use the remaining 30% for testing\n",
        "test_data = ICU_df.drop(train_data.index)\n",
        "\n",
        "# Check the mean of the 'hospital_death' column in both training and testing data\n",
        "train_data['hospital_death'].mean()\n",
        "test_data['hospital_death'].mean()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "d5MQsUPA2zF2"
      },
      "outputs": [],
      "source": [
        "# Data Preparation\n",
        "\n",
        "# Extract the 'DEATH_EVENT' column as the target variable for training and testing\n",
        "Y_train = train_data['hospital_death'].to_numpy()\n",
        "Y_test = test_data['hospital_death'].to_numpy()\n",
        "\n",
        "# Extract the features (excluding 'hospital_death') for training and testing\n",
        "X_train = train_data.drop('hospital_death', axis=1).to_numpy()\n",
        "X_test = test_data.drop('hospital_death', axis=1).to_numpy()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Replace NaN values with the median of each column\n",
        "X_train = pd.DataFrame(X_train).fillna(pd.DataFrame(X_train).median()).values\n",
        "X_test = pd.DataFrame(X_test).fillna(pd.DataFrame(X_test).median()).values"
      ],
      "metadata": {
        "id": "ejHn0dx0rv0w"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "bsXWZYT-dA3v",
        "outputId": "0d89bdc3-4965-43e9-b169-e6d3d1a33632"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-37-daad8122366c>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Convert numpy arrays back to DataFrames\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mX_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mX_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'columns' is not defined"
          ]
        }
      ],
      "source": [
        "# Convert numpy arrays back to DataFrames\n",
        "X_train = pd.DataFrame(X_train, columns=columns)\n",
        "X_test = pd.DataFrame(X_test, columns=columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2dCIRj_eNdKZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        },
        "outputId": "4006e3f5-2ece-46d0-df7d-4fdee54c5bb7"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-133-289de4d6d3ab>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Initializing a column transformer that will handle categorical data encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m ct = ColumnTransformer([('one_hot_encoder', OneHotEncoder(), [c for c in categorical_columns]),\n\u001b[0m\u001b[1;32m      3\u001b[0m                         ('target_encoder', TargetEncoder(),categorical_columns)],\n\u001b[1;32m      4\u001b[0m                        remainder='passthrough')\n",
            "\u001b[0;31mNameError\u001b[0m: name 'categorical_columns' is not defined"
          ]
        }
      ],
      "source": [
        "# Initializing a column transformer that will handle categorical data encoding\n",
        "ct = ColumnTransformer([('one_hot_encoder', OneHotEncoder(), [c for c in categorical_columns]),\n",
        "                        ('target_encoder', TargetEncoder(),categorical_columns)],\n",
        "                       remainder='passthrough')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r0_bLrCUVy_W"
      },
      "outputs": [],
      "source": [
        "#Fit the ColumnTransformer to the data\n",
        "ct.fit(X_train, Y_train)\n",
        "\n",
        "# transform training data and convert DF with new column names\n",
        "X_train = pd.DataFrame(ct.fit_transform(X_train, Y_train), columns=ct.get_feature_names_out())\n",
        "X_test = pd.DataFrame(ct.fit_transform(X_test, Y_test), columns=ct.get_feature_names_out())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sucrf_rE2Yni",
        "outputId": "6b98443f-23d6-4a19-c210-ae35d05a5102"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.08616956650415115"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "train_data['hospital_death'].mean()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iUyOlEMx6MEC",
        "outputId": "36a11c31-a448-4779-d4bf-cdce4a8014d4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "column encounter_id dtype[class: <class 'numpy.dtype[int64]'>; name: int64; code: <i8; kind: i]\n",
            "column patient_id dtype[class: <class 'numpy.dtype[int64]'>; name: int64; code: <i8; kind: i]\n",
            "column hospital_id dtype[class: <class 'numpy.dtype[int64]'>; name: int64; code: <i8; kind: i]\n",
            "column hospital_death dtype[class: <class 'numpy.dtype[int64]'>; name: int64; code: <i8; kind: i]\n",
            "column age dtype[class: <class 'numpy.dtype[float64]'>; name: float64; code: <f8; kind: f]\n",
            "column bmi dtype[class: <class 'numpy.dtype[float64]'>; name: float64; code: <f8; kind: f]\n",
            "column elective_surgery dtype[class: <class 'numpy.dtype[int64]'>; name: int64; code: <i8; kind: i]\n",
            "column ethnicity dtype[class: <class 'numpy.dtype[object_]'>; name: object; code: |O; kind: O]\n",
            "column gender dtype[class: <class 'numpy.dtype[object_]'>; name: object; code: |O; kind: O]\n",
            "column height dtype[class: <class 'numpy.dtype[float64]'>; name: float64; code: <f8; kind: f]\n",
            "column hospital_admit_source dtype[class: <class 'numpy.dtype[object_]'>; name: object; code: |O; kind: O]\n",
            "column icu_admit_source dtype[class: <class 'numpy.dtype[object_]'>; name: object; code: |O; kind: O]\n",
            "column icu_id dtype[class: <class 'numpy.dtype[int64]'>; name: int64; code: <i8; kind: i]\n",
            "column icu_stay_type dtype[class: <class 'numpy.dtype[object_]'>; name: object; code: |O; kind: O]\n",
            "column icu_type dtype[class: <class 'numpy.dtype[object_]'>; name: object; code: |O; kind: O]\n",
            "column pre_icu_los_days dtype[class: <class 'numpy.dtype[float64]'>; name: float64; code: <f8; kind: f]\n",
            "column readmission_status dtype[class: <class 'numpy.dtype[int64]'>; name: int64; code: <i8; kind: i]\n",
            "column weight dtype[class: <class 'numpy.dtype[float64]'>; name: float64; code: <f8; kind: f]\n",
            "column albumin_apache dtype[class: <class 'numpy.dtype[float64]'>; name: float64; code: <f8; kind: f]\n",
            "column apache_2_diagnosis dtype[class: <class 'numpy.dtype[float64]'>; name: float64; code: <f8; kind: f]\n",
            "column apache_3j_diagnosis dtype[class: <class 'numpy.dtype[float64]'>; name: float64; code: <f8; kind: f]\n",
            "column apache_post_operative dtype[class: <class 'numpy.dtype[int64]'>; name: int64; code: <i8; kind: i]\n",
            "column arf_apache dtype[class: <class 'numpy.dtype[float64]'>; name: float64; code: <f8; kind: f]\n",
            "column bilirubin_apache dtype[class: <class 'numpy.dtype[float64]'>; name: float64; code: <f8; kind: f]\n",
            "column bun_apache dtype[class: <class 'numpy.dtype[float64]'>; name: float64; code: <f8; kind: f]\n",
            "column creatinine_apache dtype[class: <class 'numpy.dtype[float64]'>; name: float64; code: <f8; kind: f]\n",
            "column fio2_apache dtype[class: <class 'numpy.dtype[float64]'>; name: float64; code: <f8; kind: f]\n",
            "column gcs_eyes_apache dtype[class: <class 'numpy.dtype[float64]'>; name: float64; code: <f8; kind: f]\n",
            "column gcs_motor_apache dtype[class: <class 'numpy.dtype[float64]'>; name: float64; code: <f8; kind: f]\n",
            "column gcs_unable_apache dtype[class: <class 'numpy.dtype[float64]'>; name: float64; code: <f8; kind: f]\n",
            "column gcs_verbal_apache dtype[class: <class 'numpy.dtype[float64]'>; name: float64; code: <f8; kind: f]\n",
            "column glucose_apache dtype[class: <class 'numpy.dtype[float64]'>; name: float64; code: <f8; kind: f]\n",
            "column heart_rate_apache dtype[class: <class 'numpy.dtype[float64]'>; name: float64; code: <f8; kind: f]\n",
            "column hematocrit_apache dtype[class: <class 'numpy.dtype[float64]'>; name: float64; code: <f8; kind: f]\n",
            "column intubated_apache dtype[class: <class 'numpy.dtype[float64]'>; name: float64; code: <f8; kind: f]\n",
            "column map_apache dtype[class: <class 'numpy.dtype[float64]'>; name: float64; code: <f8; kind: f]\n",
            "column paco2_apache dtype[class: <class 'numpy.dtype[float64]'>; name: float64; code: <f8; kind: f]\n",
            "column paco2_for_ph_apache dtype[class: <class 'numpy.dtype[float64]'>; name: float64; code: <f8; kind: f]\n",
            "column pao2_apache dtype[class: <class 'numpy.dtype[float64]'>; name: float64; code: <f8; kind: f]\n",
            "column ph_apache dtype[class: <class 'numpy.dtype[float64]'>; name: float64; code: <f8; kind: f]\n",
            "column resprate_apache dtype[class: <class 'numpy.dtype[float64]'>; name: float64; code: <f8; kind: f]\n",
            "column sodium_apache dtype[class: <class 'numpy.dtype[float64]'>; name: float64; code: <f8; kind: f]\n",
            "column temp_apache dtype[class: <class 'numpy.dtype[float64]'>; name: float64; code: <f8; kind: f]\n",
            "column urineoutput_apache dtype[class: <class 'numpy.dtype[float64]'>; name: float64; code: <f8; kind: f]\n",
            "column ventilated_apache dtype[class: <class 'numpy.dtype[float64]'>; name: float64; code: <f8; kind: f]\n",
            "column wbc_apache dtype[class: <class 'numpy.dtype[float64]'>; name: float64; code: <f8; kind: f]\n",
            "column d1_diasbp_invasive_max dtype[class: <class 'numpy.dtype[float64]'>; name: float64; code: <f8; kind: f]\n",
            "column d1_diasbp_invasive_min dtype[class: <class 'numpy.dtype[float64]'>; name: float64; code: <f8; kind: f]\n",
            "column d1_diasbp_max dtype[class: <class 'numpy.dtype[float64]'>; name: float64; code: <f8; kind: f]\n",
            "column d1_diasbp_min dtype[class: <class 'numpy.dtype[float64]'>; name: float64; code: <f8; kind: f]\n",
            "column d1_diasbp_noninvasive_max dtype[class: <class 'numpy.dtype[float64]'>; name: float64; code: <f8; kind: f]\n",
            "column d1_diasbp_noninvasive_min dtype[class: <class 'numpy.dtype[float64]'>; name: float64; code: <f8; kind: f]\n",
            "column d1_heartrate_max dtype[class: <class 'numpy.dtype[float64]'>; name: float64; code: <f8; kind: f]\n",
            "column d1_heartrate_min dtype[class: <class 'numpy.dtype[float64]'>; name: float64; code: <f8; kind: f]\n",
            "column d1_mbp_invasive_max dtype[class: <class 'numpy.dtype[float64]'>; name: float64; code: <f8; kind: f]\n",
            "column d1_mbp_invasive_min dtype[class: <class 'numpy.dtype[float64]'>; name: float64; code: <f8; kind: f]\n",
            "column d1_mbp_max dtype[class: <class 'numpy.dtype[float64]'>; name: float64; code: <f8; kind: f]\n",
            "column d1_mbp_min dtype[class: <class 'numpy.dtype[float64]'>; name: float64; code: <f8; kind: f]\n",
            "column d1_mbp_noninvasive_max dtype[class: <class 'numpy.dtype[float64]'>; name: float64; code: <f8; kind: f]\n",
            "column d1_mbp_noninvasive_min dtype[class: <class 'numpy.dtype[float64]'>; name: float64; code: <f8; kind: f]\n",
            "column d1_resprate_max dtype[class: <class 'numpy.dtype[float64]'>; name: float64; code: <f8; kind: f]\n",
            "column d1_resprate_min dtype[class: <class 'numpy.dtype[float64]'>; name: float64; code: <f8; kind: f]\n",
            "column d1_spo2_max dtype[class: <class 'numpy.dtype[float64]'>; name: float64; code: <f8; kind: f]\n",
            "column d1_spo2_min dtype[class: <class 'numpy.dtype[float64]'>; name: float64; code: <f8; kind: f]\n",
            "column d1_sysbp_invasive_max dtype[class: <class 'numpy.dtype[float64]'>; name: float64; code: <f8; kind: f]\n",
            "column d1_sysbp_invasive_min dtype[class: <class 'numpy.dtype[float64]'>; name: float64; code: <f8; kind: f]\n",
            "column d1_sysbp_max dtype[class: <class 'numpy.dtype[float64]'>; name: float64; code: <f8; kind: f]\n",
            "column d1_sysbp_min dtype[class: <class 'numpy.dtype[float64]'>; name: float64; code: <f8; kind: f]\n",
            "column d1_sysbp_noninvasive_max dtype[class: <class 'numpy.dtype[float64]'>; name: float64; code: <f8; kind: f]\n",
            "column d1_sysbp_noninvasive_min dtype[class: <class 'numpy.dtype[float64]'>; name: float64; code: <f8; kind: f]\n",
            "column d1_temp_max dtype[class: <class 'numpy.dtype[float64]'>; name: float64; code: <f8; kind: f]\n",
            "column d1_temp_min dtype[class: <class 'numpy.dtype[float64]'>; name: float64; code: <f8; kind: f]\n",
            "column h1_diasbp_invasive_max dtype[class: <class 'numpy.dtype[float64]'>; name: float64; code: <f8; kind: f]\n",
            "column h1_diasbp_invasive_min dtype[class: <class 'numpy.dtype[float64]'>; name: float64; code: <f8; kind: f]\n",
            "column h1_diasbp_max dtype[class: <class 'numpy.dtype[float64]'>; name: float64; code: <f8; kind: f]\n",
            "column h1_diasbp_min dtype[class: <class 'numpy.dtype[float64]'>; name: float64; code: <f8; kind: f]\n",
            "column h1_diasbp_noninvasive_max dtype[class: <class 'numpy.dtype[float64]'>; name: float64; code: <f8; kind: f]\n",
            "column h1_diasbp_noninvasive_min dtype[class: <class 'numpy.dtype[float64]'>; name: float64; code: <f8; kind: f]\n",
            "column h1_heartrate_max dtype[class: <class 'numpy.dtype[float64]'>; name: float64; code: <f8; kind: f]\n",
            "column h1_heartrate_min dtype[class: <class 'numpy.dtype[float64]'>; name: float64; code: <f8; kind: f]\n",
            "column h1_mbp_invasive_max dtype[class: <class 'numpy.dtype[float64]'>; name: float64; code: <f8; kind: f]\n",
            "column h1_mbp_invasive_min dtype[class: <class 'numpy.dtype[float64]'>; name: float64; code: <f8; kind: f]\n",
            "column h1_mbp_max dtype[class: <class 'numpy.dtype[float64]'>; name: float64; code: <f8; kind: f]\n",
            "column h1_mbp_min dtype[class: <class 'numpy.dtype[float64]'>; name: float64; code: <f8; kind: f]\n",
            "column h1_mbp_noninvasive_max dtype[class: <class 'numpy.dtype[float64]'>; name: float64; code: <f8; kind: f]\n",
            "column h1_mbp_noninvasive_min dtype[class: <class 'numpy.dtype[float64]'>; name: float64; code: <f8; kind: f]\n",
            "column h1_resprate_max dtype[class: <class 'numpy.dtype[float64]'>; name: float64; code: <f8; kind: f]\n",
            "column h1_resprate_min dtype[class: <class 'numpy.dtype[float64]'>; name: float64; code: <f8; kind: f]\n",
            "column h1_spo2_max dtype[class: <class 'numpy.dtype[float64]'>; name: float64; code: <f8; kind: f]\n",
            "column h1_spo2_min dtype[class: <class 'numpy.dtype[float64]'>; name: float64; code: <f8; kind: f]\n",
            "column h1_sysbp_invasive_max dtype[class: <class 'numpy.dtype[float64]'>; name: float64; code: <f8; kind: f]\n",
            "column h1_sysbp_invasive_min dtype[class: <class 'numpy.dtype[float64]'>; name: float64; code: <f8; kind: f]\n",
            "column h1_sysbp_max dtype[class: <class 'numpy.dtype[float64]'>; name: float64; code: <f8; kind: f]\n",
            "column h1_sysbp_min dtype[class: <class 'numpy.dtype[float64]'>; name: float64; code: <f8; kind: f]\n",
            "column h1_sysbp_noninvasive_max dtype[class: <class 'numpy.dtype[float64]'>; name: float64; code: <f8; kind: f]\n",
            "column h1_sysbp_noninvasive_min dtype[class: <class 'numpy.dtype[float64]'>; name: float64; code: <f8; kind: f]\n",
            "column h1_temp_max dtype[class: <class 'numpy.dtype[float64]'>; name: float64; code: <f8; kind: f]\n",
            "column h1_temp_min dtype[class: <class 'numpy.dtype[float64]'>; name: float64; code: <f8; kind: f]\n",
            "column d1_albumin_max dtype[class: <class 'numpy.dtype[float64]'>; name: float64; code: <f8; kind: f]\n",
            "column d1_albumin_min dtype[class: <class 'numpy.dtype[float64]'>; name: float64; code: <f8; kind: f]\n",
            "column d1_bilirubin_max dtype[class: <class 'numpy.dtype[float64]'>; name: float64; code: <f8; kind: f]\n",
            "column d1_bilirubin_min dtype[class: <class 'numpy.dtype[float64]'>; name: float64; code: <f8; kind: f]\n",
            "column d1_bun_max dtype[class: <class 'numpy.dtype[float64]'>; name: float64; code: <f8; kind: f]\n",
            "column d1_bun_min dtype[class: <class 'numpy.dtype[float64]'>; name: float64; code: <f8; kind: f]\n",
            "column d1_calcium_max dtype[class: <class 'numpy.dtype[float64]'>; name: float64; code: <f8; kind: f]\n",
            "column d1_calcium_min dtype[class: <class 'numpy.dtype[float64]'>; name: float64; code: <f8; kind: f]\n",
            "column d1_creatinine_max dtype[class: <class 'numpy.dtype[float64]'>; name: float64; code: <f8; kind: f]\n",
            "column d1_creatinine_min dtype[class: <class 'numpy.dtype[float64]'>; name: float64; code: <f8; kind: f]\n",
            "column d1_glucose_max dtype[class: <class 'numpy.dtype[float64]'>; name: float64; code: <f8; kind: f]\n",
            "column d1_glucose_min dtype[class: <class 'numpy.dtype[float64]'>; name: float64; code: <f8; kind: f]\n",
            "column d1_hco3_max dtype[class: <class 'numpy.dtype[float64]'>; name: float64; code: <f8; kind: f]\n",
            "column d1_hco3_min dtype[class: <class 'numpy.dtype[float64]'>; name: float64; code: <f8; kind: f]\n",
            "column d1_hemaglobin_max dtype[class: <class 'numpy.dtype[float64]'>; name: float64; code: <f8; kind: f]\n",
            "column d1_hemaglobin_min dtype[class: <class 'numpy.dtype[float64]'>; name: float64; code: <f8; kind: f]\n",
            "column d1_hematocrit_max dtype[class: <class 'numpy.dtype[float64]'>; name: float64; code: <f8; kind: f]\n",
            "column d1_hematocrit_min dtype[class: <class 'numpy.dtype[float64]'>; name: float64; code: <f8; kind: f]\n",
            "column d1_inr_max dtype[class: <class 'numpy.dtype[float64]'>; name: float64; code: <f8; kind: f]\n",
            "column d1_inr_min dtype[class: <class 'numpy.dtype[float64]'>; name: float64; code: <f8; kind: f]\n",
            "column d1_lactate_max dtype[class: <class 'numpy.dtype[float64]'>; name: float64; code: <f8; kind: f]\n",
            "column d1_lactate_min dtype[class: <class 'numpy.dtype[float64]'>; name: float64; code: <f8; kind: f]\n",
            "column d1_platelets_max dtype[class: <class 'numpy.dtype[float64]'>; name: float64; code: <f8; kind: f]\n",
            "column d1_platelets_min dtype[class: <class 'numpy.dtype[float64]'>; name: float64; code: <f8; kind: f]\n",
            "column d1_potassium_max dtype[class: <class 'numpy.dtype[float64]'>; name: float64; code: <f8; kind: f]\n",
            "column d1_potassium_min dtype[class: <class 'numpy.dtype[float64]'>; name: float64; code: <f8; kind: f]\n",
            "column d1_sodium_max dtype[class: <class 'numpy.dtype[float64]'>; name: float64; code: <f8; kind: f]\n",
            "column d1_sodium_min dtype[class: <class 'numpy.dtype[float64]'>; name: float64; code: <f8; kind: f]\n",
            "column d1_wbc_max dtype[class: <class 'numpy.dtype[float64]'>; name: float64; code: <f8; kind: f]\n",
            "column d1_wbc_min dtype[class: <class 'numpy.dtype[float64]'>; name: float64; code: <f8; kind: f]\n",
            "column h1_albumin_max dtype[class: <class 'numpy.dtype[float64]'>; name: float64; code: <f8; kind: f]\n",
            "column h1_albumin_min dtype[class: <class 'numpy.dtype[float64]'>; name: float64; code: <f8; kind: f]\n",
            "column h1_bilirubin_max dtype[class: <class 'numpy.dtype[float64]'>; name: float64; code: <f8; kind: f]\n",
            "column h1_bilirubin_min dtype[class: <class 'numpy.dtype[float64]'>; name: float64; code: <f8; kind: f]\n",
            "column h1_bun_max dtype[class: <class 'numpy.dtype[float64]'>; name: float64; code: <f8; kind: f]\n",
            "column h1_bun_min dtype[class: <class 'numpy.dtype[float64]'>; name: float64; code: <f8; kind: f]\n",
            "column h1_calcium_max dtype[class: <class 'numpy.dtype[float64]'>; name: float64; code: <f8; kind: f]\n",
            "column h1_calcium_min dtype[class: <class 'numpy.dtype[float64]'>; name: float64; code: <f8; kind: f]\n",
            "column h1_creatinine_max dtype[class: <class 'numpy.dtype[float64]'>; name: float64; code: <f8; kind: f]\n",
            "column h1_creatinine_min dtype[class: <class 'numpy.dtype[float64]'>; name: float64; code: <f8; kind: f]\n",
            "column h1_glucose_max dtype[class: <class 'numpy.dtype[float64]'>; name: float64; code: <f8; kind: f]\n",
            "column h1_glucose_min dtype[class: <class 'numpy.dtype[float64]'>; name: float64; code: <f8; kind: f]\n",
            "column h1_hco3_max dtype[class: <class 'numpy.dtype[float64]'>; name: float64; code: <f8; kind: f]\n",
            "column h1_hco3_min dtype[class: <class 'numpy.dtype[float64]'>; name: float64; code: <f8; kind: f]\n",
            "column h1_hemaglobin_max dtype[class: <class 'numpy.dtype[float64]'>; name: float64; code: <f8; kind: f]\n",
            "column h1_hemaglobin_min dtype[class: <class 'numpy.dtype[float64]'>; name: float64; code: <f8; kind: f]\n",
            "column h1_hematocrit_max dtype[class: <class 'numpy.dtype[float64]'>; name: float64; code: <f8; kind: f]\n",
            "column h1_hematocrit_min dtype[class: <class 'numpy.dtype[float64]'>; name: float64; code: <f8; kind: f]\n",
            "column h1_inr_max dtype[class: <class 'numpy.dtype[float64]'>; name: float64; code: <f8; kind: f]\n",
            "column h1_inr_min dtype[class: <class 'numpy.dtype[float64]'>; name: float64; code: <f8; kind: f]\n",
            "column h1_lactate_max dtype[class: <class 'numpy.dtype[float64]'>; name: float64; code: <f8; kind: f]\n",
            "column h1_lactate_min dtype[class: <class 'numpy.dtype[float64]'>; name: float64; code: <f8; kind: f]\n",
            "column h1_platelets_max dtype[class: <class 'numpy.dtype[float64]'>; name: float64; code: <f8; kind: f]\n",
            "column h1_platelets_min dtype[class: <class 'numpy.dtype[float64]'>; name: float64; code: <f8; kind: f]\n",
            "column h1_potassium_max dtype[class: <class 'numpy.dtype[float64]'>; name: float64; code: <f8; kind: f]\n",
            "column h1_potassium_min dtype[class: <class 'numpy.dtype[float64]'>; name: float64; code: <f8; kind: f]\n",
            "column h1_sodium_max dtype[class: <class 'numpy.dtype[float64]'>; name: float64; code: <f8; kind: f]\n",
            "column h1_sodium_min dtype[class: <class 'numpy.dtype[float64]'>; name: float64; code: <f8; kind: f]\n",
            "column h1_wbc_max dtype[class: <class 'numpy.dtype[float64]'>; name: float64; code: <f8; kind: f]\n",
            "column h1_wbc_min dtype[class: <class 'numpy.dtype[float64]'>; name: float64; code: <f8; kind: f]\n",
            "column d1_arterial_pco2_max dtype[class: <class 'numpy.dtype[float64]'>; name: float64; code: <f8; kind: f]\n",
            "column d1_arterial_pco2_min dtype[class: <class 'numpy.dtype[float64]'>; name: float64; code: <f8; kind: f]\n",
            "column d1_arterial_ph_max dtype[class: <class 'numpy.dtype[float64]'>; name: float64; code: <f8; kind: f]\n",
            "column d1_arterial_ph_min dtype[class: <class 'numpy.dtype[float64]'>; name: float64; code: <f8; kind: f]\n",
            "column d1_arterial_po2_max dtype[class: <class 'numpy.dtype[float64]'>; name: float64; code: <f8; kind: f]\n",
            "column d1_arterial_po2_min dtype[class: <class 'numpy.dtype[float64]'>; name: float64; code: <f8; kind: f]\n",
            "column d1_pao2fio2ratio_max dtype[class: <class 'numpy.dtype[float64]'>; name: float64; code: <f8; kind: f]\n",
            "column d1_pao2fio2ratio_min dtype[class: <class 'numpy.dtype[float64]'>; name: float64; code: <f8; kind: f]\n",
            "column h1_arterial_pco2_max dtype[class: <class 'numpy.dtype[float64]'>; name: float64; code: <f8; kind: f]\n",
            "column h1_arterial_pco2_min dtype[class: <class 'numpy.dtype[float64]'>; name: float64; code: <f8; kind: f]\n",
            "column h1_arterial_ph_max dtype[class: <class 'numpy.dtype[float64]'>; name: float64; code: <f8; kind: f]\n",
            "column h1_arterial_ph_min dtype[class: <class 'numpy.dtype[float64]'>; name: float64; code: <f8; kind: f]\n",
            "column h1_arterial_po2_max dtype[class: <class 'numpy.dtype[float64]'>; name: float64; code: <f8; kind: f]\n",
            "column h1_arterial_po2_min dtype[class: <class 'numpy.dtype[float64]'>; name: float64; code: <f8; kind: f]\n",
            "column h1_pao2fio2ratio_max dtype[class: <class 'numpy.dtype[float64]'>; name: float64; code: <f8; kind: f]\n",
            "column h1_pao2fio2ratio_min dtype[class: <class 'numpy.dtype[float64]'>; name: float64; code: <f8; kind: f]\n",
            "column apache_4a_hospital_death_prob dtype[class: <class 'numpy.dtype[float64]'>; name: float64; code: <f8; kind: f]\n",
            "column apache_4a_icu_death_prob dtype[class: <class 'numpy.dtype[float64]'>; name: float64; code: <f8; kind: f]\n",
            "column aids dtype[class: <class 'numpy.dtype[float64]'>; name: float64; code: <f8; kind: f]\n",
            "column cirrhosis dtype[class: <class 'numpy.dtype[float64]'>; name: float64; code: <f8; kind: f]\n",
            "column diabetes_mellitus dtype[class: <class 'numpy.dtype[float64]'>; name: float64; code: <f8; kind: f]\n",
            "column hepatic_failure dtype[class: <class 'numpy.dtype[float64]'>; name: float64; code: <f8; kind: f]\n",
            "column immunosuppression dtype[class: <class 'numpy.dtype[float64]'>; name: float64; code: <f8; kind: f]\n",
            "column leukemia dtype[class: <class 'numpy.dtype[float64]'>; name: float64; code: <f8; kind: f]\n",
            "column lymphoma dtype[class: <class 'numpy.dtype[float64]'>; name: float64; code: <f8; kind: f]\n",
            "column solid_tumor_with_metastasis dtype[class: <class 'numpy.dtype[float64]'>; name: float64; code: <f8; kind: f]\n",
            "column apache_3j_bodysystem dtype[class: <class 'numpy.dtype[object_]'>; name: object; code: |O; kind: O]\n",
            "column apache_2_bodysystem dtype[class: <class 'numpy.dtype[object_]'>; name: object; code: |O; kind: O]\n"
          ]
        }
      ],
      "source": [
        "dts = df.dtypes\n",
        "for index, value in dts.items():\n",
        "    print(\"column %s dtype[class: %s; name: %s; code: %s; kind: %s]\" % (index, type(value), value.name, value.str, value.kind))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HpRdigzW6cPi",
        "outputId": "873a4759-f1bd-4487-8117-70520c87ed4a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "patient_id                       int64\n",
              "hospital_id                      int64\n",
              "hospital_death                   int64\n",
              "age                            float64\n",
              "bmi                            float64\n",
              "                                ...   \n",
              "hepatic_failure                float64\n",
              "immunosuppression              float64\n",
              "leukemia                       float64\n",
              "lymphoma                       float64\n",
              "solid_tumor_with_metastasis    float64\n",
              "Length: 178, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "ICU_df.dtypes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "bkFRvRSj29mu"
      },
      "outputs": [],
      "source": [
        "# Standardize the features to have zero mean and unit variance\n",
        "sc = StandardScaler()\n",
        "X_train = sc.fit_transform(X_train)\n",
        "X_test = sc.transform(X_test)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Scale the data to the range of 0 and 1\n",
        "X_train = (X_train - X_train.min()) / (X_train.max() - X_train.min())\n",
        "X_test = (X_test - X_test.min()) / (X_test.max() - X_test.min())"
      ],
      "metadata": {
        "id": "J_fFgREVon_4"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "ep3t45zm8zmA"
      },
      "outputs": [],
      "source": [
        "# Define the number of neurons in the first and second hidden layers\n",
        "hidden_units_layer_1 = 5\n",
        "hidden_units_layer_2 = 5\n",
        "\n",
        "# FIRST LAYER: Define weights and biases for the first layer\n",
        "W1 = t.randn((177, hidden_units_layer_1), requires_grad=True)\n",
        "B1 = t.zeros((1, hidden_units_layer_1), requires_grad=True)\n",
        "\n",
        "# SECOND LAYER: Define weights and biases for the second layer\n",
        "W2 = t.randn((hidden_units_layer_1, hidden_units_layer_2), requires_grad=True)\n",
        "B2 = t.zeros((1, hidden_units_layer_2), requires_grad=True)\n",
        "\n",
        "# THIRD LAYER: Define weights and biases for the output layer\n",
        "W3 = t.randn((hidden_units_layer_2, 1), requires_grad=True)\n",
        "B3 = t.zeros((1, 1), requires_grad=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "BFvrzPZM817R"
      },
      "outputs": [],
      "source": [
        "# Define the forward pass of the neural network\n",
        "def forward(input):\n",
        "    # First hidden layer with tanh activation\n",
        "    out = sigmoid(tanh(input @ W1 + B1))\n",
        "\n",
        "    # Second hidden layer with tanh activation\n",
        "    out = sigmoid(tanh(out @ W2 + B2))\n",
        "\n",
        "    # Output layer with sigmoid activation (since it's a binary classification problem)\n",
        "    out = sigmoid(out @ W3 + B3)\n",
        "    return out\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "ZhgydaSh86ZA"
      },
      "outputs": [],
      "source": [
        "# Convert the training data to PyTorch tensors\n",
        "X = t.Tensor(X_train).type(t.float32)\n",
        "Y = t.Tensor(Y_train).type(t.float32)\n",
        "\n",
        "# Create a dataset from tensors to be used with DataLoader\n",
        "train_dataset = TensorDataset(X, Y)\n",
        "\n",
        "# Define training hyperparameters\n",
        "epochs = 500\n",
        "learning_rate = 0.01\n",
        "batch_size = 32\n",
        "\n",
        "# DataLoader provides batches of data for training\n",
        "train_data_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "# Define the optimizer (Adam) and include all weights and biases\n",
        "optimizer = Adam([W1, B1, W2, B2, W3, B3], lr=learning_rate)\n",
        "\n",
        "# Define the loss function (Binary Cross-Entropy Loss)\n",
        "loss_fn = t.nn.BCELoss()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking the shape of the input tensor\n",
        "print(\"Input shape:\", X.shape)\n",
        "\n",
        "# Checking the shapes of the weights and biases\n",
        "print(\"W1 shape:\", W1.shape)\n",
        "print(\"B1 shape:\", B1.shape)\n",
        "print(\"W2 shape:\", W2.shape)\n",
        "print(\"B2 shape:\", B2.shape)\n",
        "print(\"W3 shape:\", W3.shape)\n",
        "print(\"B3 shape:\", B3.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sufI-NqGlI6I",
        "outputId": "76487a0d-a5c6-4f5e-fe4f-8c2310ed2579"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input shape: torch.Size([64199, 177])\n",
            "W1 shape: torch.Size([177, 5])\n",
            "B1 shape: torch.Size([1, 5])\n",
            "W2 shape: torch.Size([5, 5])\n",
            "B2 shape: torch.Size([1, 5])\n",
            "W3 shape: torch.Size([5, 1])\n",
            "B3 shape: torch.Size([1, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking the data type of tensors, weights, and biases\n",
        "print(\"Data type of X:\", X.dtype)\n",
        "print(\"Data type of W1:\", W1.dtype)\n",
        "print(\"Data type of B1:\", B1.dtype)\n",
        "print(\"Data type of W2:\", W2.dtype)\n",
        "print(\"Data type of B2:\", B2.dtype)\n",
        "print(\"Data type of W3:\", W3.dtype)\n",
        "print(\"Data type of B3:\", B3.dtype)\n",
        "\n",
        "# Inspecting the contents of tensors, weights, and biases\n",
        "print(\"Content of X:\", X)\n",
        "print(\"Content of W1:\", W1)\n",
        "print(\"Content of B1:\", B1)\n",
        "print(\"Content of W2:\", W2)\n",
        "print(\"Content of B2:\", B2)\n",
        "print(\"Content of W3:\", W3)\n",
        "print(\"Content of B3:\", B3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y1bzIKs1mPyG",
        "outputId": "bdefd7cb-ae93-4b97-c070-4b0a8f6928cd"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data type of X: torch.float32\n",
            "Data type of W1: torch.float32\n",
            "Data type of B1: torch.float32\n",
            "Data type of W2: torch.float32\n",
            "Data type of B2: torch.float32\n",
            "Data type of W3: torch.float32\n",
            "Data type of B3: torch.float32\n",
            "Content of X: tensor([[0.4401, 0.4505, 0.4303,  ..., 0.4421, 0.4423, 0.4416],\n",
            "        [0.4294, 0.4394, 0.4450,  ..., 0.4421, 0.4423, 0.4416],\n",
            "        [0.4467, 0.4484, 0.4514,  ..., 0.4421, 0.4423, 0.4416],\n",
            "        ...,\n",
            "        [0.4424, 0.4436, 0.4362,  ..., 0.4421, 0.4423, 0.4416],\n",
            "        [0.4506, 0.4394, 0.4249,  ..., 0.4421, 0.4423, 0.4416],\n",
            "        [0.4542, 0.4311, 0.4460,  ..., 0.4421, 0.4423, 0.4416]])\n",
            "Content of W1: tensor([[-1.3893e-01,  6.1967e-01, -1.1718e+00, -6.3836e-02,  7.5086e-01],\n",
            "        [ 1.1750e+00, -1.1519e+00, -7.5894e-01, -2.9680e-01,  1.1801e+00],\n",
            "        [ 2.3962e-01,  1.2644e+00, -1.7829e+00,  1.4209e-01, -2.1341e+00],\n",
            "        [ 1.0674e-01,  4.6819e-01,  7.4607e-01,  4.1938e-01,  2.0290e+00],\n",
            "        [ 1.4962e+00,  1.2661e+00, -3.0152e-01, -6.4392e-01, -2.8185e-01],\n",
            "        [-9.4903e-01,  4.6808e-01, -2.9308e-01, -6.0196e-01,  2.0034e-01],\n",
            "        [ 2.7758e-02,  8.1887e-01, -2.5505e+00, -6.3007e-01, -3.1614e-02],\n",
            "        [-2.2271e-01, -5.3296e-01,  1.0073e+00,  6.6064e-01, -6.8040e-01],\n",
            "        [-5.8292e-01,  8.8562e-01, -9.7854e-01,  2.0534e+00,  1.8991e+00],\n",
            "        [ 1.3120e+00, -2.0327e+00, -2.1576e+00, -3.4804e-01,  8.9118e-03],\n",
            "        [-7.5618e-01, -5.5567e-01,  2.3444e-01, -1.8529e+00, -1.7182e-01],\n",
            "        [-1.3949e+00, -1.2272e+00,  7.1134e-01, -1.1760e+00,  8.7632e-01],\n",
            "        [-3.1976e-01,  9.2387e-01,  8.4275e-01,  2.4712e-01,  1.4130e+00],\n",
            "        [ 6.6348e-01, -9.2876e-01,  9.8980e-01, -2.9179e-01, -8.8589e-01],\n",
            "        [ 1.1694e-01, -4.5569e-01, -1.7265e+00,  1.6971e+00, -8.5910e-01],\n",
            "        [ 6.1192e-01, -3.4728e-01,  1.5046e-01,  1.2474e+00, -3.4324e+00],\n",
            "        [-1.0147e+00,  2.1380e+00, -1.0998e+00,  3.9222e-01, -4.6709e-01],\n",
            "        [-1.5267e-01, -9.8421e-01, -8.0952e-01, -1.9257e+00, -1.0138e+00],\n",
            "        [ 2.0019e+00, -3.2533e-01, -1.0864e+00,  9.0319e-01,  1.0655e+00],\n",
            "        [-1.0043e+00,  2.4955e-01, -3.2618e-01,  1.6920e-01, -1.1986e+00],\n",
            "        [-3.3718e-01,  3.5734e-01,  1.0311e+00, -1.0385e-01, -3.5318e-01],\n",
            "        [-1.1067e+00,  1.6398e-01, -1.2023e-01, -1.2189e-01,  9.7500e-01],\n",
            "        [ 2.7582e-01, -1.1114e+00, -1.7533e+00, -7.8691e-01, -6.1174e-01],\n",
            "        [ 6.8213e-01, -2.5636e-02, -3.7088e-01, -5.5733e-01,  5.3755e-02],\n",
            "        [ 8.9774e-01,  1.0201e+00, -9.1788e-01,  1.9348e-02, -3.5249e-01],\n",
            "        [ 1.1211e+00, -2.7259e+00, -1.2823e+00,  1.0844e+00, -5.9791e-01],\n",
            "        [-1.1681e+00,  6.1126e-01, -8.8939e-01, -8.3011e-01,  8.3272e-01],\n",
            "        [ 1.7063e-01, -1.4107e-01,  1.5804e+00,  1.3367e+00, -5.0311e-01],\n",
            "        [ 1.0273e-01, -1.0316e+00,  4.2877e-01,  8.2717e-01,  9.6667e-01],\n",
            "        [-2.0119e-01, -1.1339e+00,  6.4315e-01, -5.0445e-01, -7.6680e-02],\n",
            "        [-1.2206e+00,  5.1228e-01,  3.5895e-02, -1.7318e+00,  7.2723e-01],\n",
            "        [ 7.6410e-02,  1.5486e+00,  1.1028e+00,  7.2192e-01, -3.5608e-01],\n",
            "        [ 1.2118e+00, -1.7870e-01,  9.2950e-02,  2.9222e-01, -6.5626e-01],\n",
            "        [-2.5943e-01, -1.8440e-01,  1.0073e-01, -1.2118e+00, -1.6946e-01],\n",
            "        [-1.4642e-01,  2.0152e-01,  1.4452e+00,  1.0763e+00, -7.8377e-03],\n",
            "        [ 1.6972e+00, -3.8428e-01, -9.5303e-01,  1.0916e+00, -1.5416e+00],\n",
            "        [ 9.9725e-01,  1.3532e+00, -1.3189e+00, -1.0349e+00, -1.8061e+00],\n",
            "        [-4.7031e-01, -6.2235e-01, -1.0352e+00,  4.4945e-01,  3.8515e-01],\n",
            "        [-1.1226e+00,  1.3879e+00,  8.7539e-01,  2.0404e-01,  5.2606e-01],\n",
            "        [-3.6010e-02,  2.3074e-01,  6.2004e-01,  1.1204e+00,  2.9497e-01],\n",
            "        [ 1.6182e-02, -7.4404e-01,  1.2727e+00, -1.4699e+00, -4.2612e-02],\n",
            "        [-1.0148e+00, -7.3456e-01,  6.2846e-01,  1.3431e+00,  4.3160e-02],\n",
            "        [ 1.7781e-01,  4.0797e-01, -7.5929e-01,  2.8433e+00,  1.0904e+00],\n",
            "        [-1.9810e+00,  1.5779e+00,  2.9537e-01,  5.4274e-01, -1.6320e+00],\n",
            "        [-1.0330e+00,  1.4201e+00,  2.7563e+00,  1.4541e+00, -4.1075e-01],\n",
            "        [-1.8281e+00,  6.1188e-01, -2.6271e-01,  5.2948e-01, -4.1093e-01],\n",
            "        [-1.1750e-01, -9.5513e-01, -1.9281e-01,  2.9975e-01, -2.6302e-01],\n",
            "        [-1.4409e+00,  1.5359e+00,  2.1294e-01, -1.7502e+00,  1.0513e+00],\n",
            "        [ 2.8727e-01,  1.7307e-01,  6.2654e-01,  2.6645e-01,  8.8358e-01],\n",
            "        [-8.6570e-02,  8.9345e-01, -4.4071e-01, -2.3674e-01,  9.9290e-01],\n",
            "        [-2.9137e-01, -9.4400e-01,  8.1214e-01,  1.4436e-01,  1.9590e+00],\n",
            "        [-2.1533e+00,  9.0650e-01,  5.0778e-01,  1.0477e+00,  1.4933e+00],\n",
            "        [-9.3195e-01, -2.7740e-01, -3.1946e-01,  4.0032e-01,  4.4671e-01],\n",
            "        [-2.3767e-01,  2.8686e-02, -4.4331e-01, -8.3820e-01,  5.3592e-01],\n",
            "        [-6.8882e-01, -1.7017e+00, -1.6117e+00,  1.1150e-01,  5.6964e-01],\n",
            "        [-1.9993e+00, -1.0344e+00, -4.2050e-01,  9.5256e-01,  2.8214e-01],\n",
            "        [-1.8426e+00,  1.0566e+00, -8.6387e-01, -1.6358e+00, -2.9843e-01],\n",
            "        [-1.3467e+00,  7.6492e-01, -1.2519e+00,  1.3472e-01, -1.0390e+00],\n",
            "        [ 3.7512e-01,  1.6604e+00, -3.9208e-01,  7.6404e-01, -2.1445e-01],\n",
            "        [ 9.1791e-01,  1.1321e+00,  6.0039e-01,  9.6272e-01,  5.1444e-01],\n",
            "        [-5.7144e-01, -4.1235e-01, -2.3203e-01,  2.2722e-01, -2.8464e-01],\n",
            "        [-1.6203e+00, -5.1525e-01,  1.6322e-01,  1.3874e+00, -1.0054e-01],\n",
            "        [ 9.0681e-01,  7.8624e-01, -6.1275e-01,  2.2803e-01,  2.0163e-01],\n",
            "        [-3.7948e-01, -2.0884e-01, -5.2440e-01,  1.6020e-02,  1.9823e+00],\n",
            "        [ 6.6097e-01, -8.1450e-01, -4.1226e-01,  1.5278e+00, -1.5369e-01],\n",
            "        [-5.0027e-01, -3.4776e-01,  7.6586e-01,  1.9991e+00, -1.5930e-01],\n",
            "        [ 1.0525e+00,  1.2312e+00, -5.7242e-01, -2.0886e+00,  1.2358e+00],\n",
            "        [-1.2109e+00, -1.5591e+00,  3.9360e-01,  8.9816e-01, -5.4003e-01],\n",
            "        [ 8.1443e-01, -5.5538e-01,  3.4970e-01, -7.8396e-02, -1.5369e+00],\n",
            "        [ 2.2858e+00, -1.0643e+00,  1.9130e+00, -1.7261e+00, -5.5495e-01],\n",
            "        [ 1.1994e+00,  7.5856e-01, -1.4072e+00,  1.9017e-01, -2.8484e-01],\n",
            "        [-9.7376e-02, -5.3787e-01,  3.2036e-01,  2.0569e-02, -2.4516e+00],\n",
            "        [ 1.0660e+00,  6.8385e-01, -1.1429e+00, -1.4383e+00, -2.3195e-01],\n",
            "        [-1.0202e+00,  1.1667e+00, -1.4594e-01,  7.1248e-01, -4.4855e-01],\n",
            "        [-3.8558e-01, -2.8709e-01,  5.9852e-01,  1.3501e+00, -1.8048e-01],\n",
            "        [ 5.5040e-01,  6.2831e-01,  1.9545e+00,  6.4089e-01, -3.5087e-01],\n",
            "        [ 4.7871e-01,  1.0684e+00, -1.0071e+00, -1.2472e-02, -2.5303e-01],\n",
            "        [ 2.8262e-01, -7.8820e-01, -2.3845e+00, -5.4695e-01, -3.8306e-01],\n",
            "        [ 1.6693e+00, -7.8172e-01, -6.7280e-01, -2.6469e+00,  4.0762e-01],\n",
            "        [-1.9191e-01, -2.9993e-02, -1.1357e+00,  8.0915e-01,  1.8364e-01],\n",
            "        [-1.4891e+00,  6.3894e-01,  6.2449e-01,  1.4441e+00, -7.0878e-01],\n",
            "        [-7.3208e-01, -5.1984e-01,  3.5732e-01, -1.9213e-01, -5.2145e-01],\n",
            "        [-9.2605e-02, -4.7469e-01, -2.9394e-01,  9.8859e-01,  4.3221e-01],\n",
            "        [-1.2292e+00,  6.8013e-01, -1.3893e+00, -1.8850e-01,  8.2453e-01],\n",
            "        [-3.4020e-01, -7.7463e-01, -1.7494e-01, -1.8229e+00,  1.0048e+00],\n",
            "        [-1.7432e+00, -9.9873e-02, -2.0155e+00, -9.1832e-01, -1.4472e-01],\n",
            "        [-1.4697e+00,  8.9016e-01, -1.1072e+00,  7.4792e-01, -2.1260e+00],\n",
            "        [-6.9338e-01,  1.4186e+00, -1.8579e-01, -1.1039e+00, -1.8165e+00],\n",
            "        [ 1.1307e-01, -6.3034e-01, -4.8008e-01,  1.6379e+00, -4.8911e-01],\n",
            "        [-1.8031e-01, -2.0819e+00, -3.0635e-01, -6.6717e-01, -3.0797e-01],\n",
            "        [-4.8096e-01, -7.0759e-01,  1.0495e+00,  7.8551e-01, -1.4629e+00],\n",
            "        [-6.8183e-02, -1.2566e+00, -1.0851e+00, -4.9470e-01, -2.8762e-01],\n",
            "        [ 1.9181e+00, -3.1123e-01, -7.2172e-01, -7.8646e-02, -5.9991e-01],\n",
            "        [ 2.9670e-01,  2.7446e-01, -3.3610e-01,  1.2256e+00,  1.9106e+00],\n",
            "        [ 1.9001e+00, -1.5646e+00,  1.1329e+00, -1.3102e+00, -3.6059e-01],\n",
            "        [-1.9629e+00, -5.6955e-01,  1.1756e+00,  1.2790e+00,  2.0177e+00],\n",
            "        [-3.2979e-01,  1.2334e+00,  1.5600e+00,  4.8308e-01,  1.6928e+00],\n",
            "        [ 4.8946e-01, -3.3495e-01,  1.0057e+00, -4.2715e-01, -1.3473e-01],\n",
            "        [ 4.8620e-01, -8.9864e-01, -2.0440e+00, -1.3076e+00,  2.0470e+00],\n",
            "        [-3.7258e-01,  1.8357e-01, -6.3148e-01,  9.5623e-01, -9.6283e-01],\n",
            "        [ 2.2898e-01,  1.4028e+00,  8.2508e-01,  8.6020e-03,  9.4120e-01],\n",
            "        [ 2.7766e+00,  8.7954e-01, -1.9867e+00, -3.6628e-01, -2.1843e-01],\n",
            "        [-8.1459e-01,  6.7350e-01,  2.0825e+00,  4.9586e-01, -9.7696e-01],\n",
            "        [ 1.8565e+00, -3.3650e-01,  1.0359e+00,  1.2568e+00,  1.9737e+00],\n",
            "        [ 9.3237e-01, -5.9046e-01, -3.8739e-01,  4.5798e-03, -4.7095e-01],\n",
            "        [-2.3617e-01,  1.4019e+00,  7.7094e-01, -7.4649e-01, -1.0331e+00],\n",
            "        [ 4.8215e-01, -1.8039e-01, -2.2325e-01,  4.8571e-01,  1.9141e+00],\n",
            "        [-1.7451e-01,  1.7152e+00, -4.8844e-01,  1.0545e+00, -1.4928e-01],\n",
            "        [-4.7343e-01,  7.0850e-01,  2.0395e+00, -5.4801e-01, -2.0565e+00],\n",
            "        [-5.8687e-01, -9.1012e-01, -1.5598e-01,  2.3718e-01, -5.4032e-01],\n",
            "        [-1.1234e-01,  5.6657e-01,  1.2244e+00,  1.2845e+00,  1.2687e+00],\n",
            "        [-3.2513e-01, -8.1616e-01,  1.7057e+00, -8.7618e-01, -4.7946e-01],\n",
            "        [ 1.4831e-01, -5.7015e-01, -6.3048e-01, -1.0787e+00, -1.3675e+00],\n",
            "        [ 3.2581e-01,  9.9913e-01,  1.8489e+00,  3.9101e-01,  9.3472e-01],\n",
            "        [-1.0775e+00, -7.9597e-01,  8.0924e-02, -4.0856e-01,  4.6041e-01],\n",
            "        [ 7.3600e-01, -8.1797e-01, -2.3901e+00,  9.3939e-01,  6.0453e-01],\n",
            "        [-1.1317e+00,  1.1028e+00,  2.9827e-01,  4.2363e-01,  1.6630e+00],\n",
            "        [-4.2437e-01, -8.0093e-01, -4.5406e-01,  1.8187e+00,  1.6849e+00],\n",
            "        [-1.1226e-01,  3.3991e-01,  1.5516e+00, -1.6250e+00, -2.6555e+00],\n",
            "        [-1.3561e+00, -7.7208e-01, -2.4340e+00, -5.1374e-01, -3.9692e-01],\n",
            "        [ 1.3845e+00, -3.8681e-01,  3.1860e-01, -1.7629e-01,  6.6592e-02],\n",
            "        [-7.1169e-01, -5.0053e-01, -8.9898e-01, -4.7201e-01,  1.0455e+00],\n",
            "        [-1.2688e-01, -9.2927e-02, -6.2129e-01,  1.0811e+00,  1.5959e-01],\n",
            "        [ 7.8349e-01,  7.0112e-01,  1.9640e+00,  1.8695e+00,  2.5560e-01],\n",
            "        [ 1.5748e+00, -5.2703e-01,  1.1827e+00,  1.0181e+00, -2.1186e-01],\n",
            "        [ 1.4705e+00, -4.3889e-01,  1.7978e-01, -1.0301e+00,  9.0803e-01],\n",
            "        [-7.0196e-01,  2.4448e-01,  3.2077e-01,  1.0310e+00, -3.4469e-01],\n",
            "        [-7.5191e-01,  1.3022e+00,  1.6151e+00,  1.1566e-01,  1.9400e+00],\n",
            "        [-2.1895e-01,  3.9119e-01,  6.7369e-01, -1.3083e+00,  4.9748e-02],\n",
            "        [ 1.0650e+00, -1.1832e+00,  1.0075e+00, -1.5718e+00,  2.2266e+00],\n",
            "        [-1.2140e+00,  2.7150e-01,  5.2892e-01,  8.5790e-02,  6.8930e-01],\n",
            "        [ 4.4165e-01,  5.6284e-01,  1.9884e+00, -8.1655e-01, -1.2255e+00],\n",
            "        [-2.9820e-01, -8.3248e-01, -1.5836e+00,  7.3320e-01, -4.8590e-01],\n",
            "        [ 1.6594e+00,  1.9753e+00, -7.1003e-02, -1.5048e+00,  1.4043e-01],\n",
            "        [-1.0862e+00,  4.5626e-01, -6.7139e-01, -3.9186e-01,  6.8212e-04],\n",
            "        [ 1.0068e+00,  7.3002e-01, -1.8300e+00,  1.2144e+00,  2.0605e+00],\n",
            "        [-1.0339e+00, -1.8769e-01,  1.2070e+00, -1.4230e+00,  1.2719e+00],\n",
            "        [ 3.3547e-01, -4.6780e-01, -1.6730e+00,  3.5276e-01,  1.1072e+00],\n",
            "        [ 2.2830e-01,  3.0412e-01,  1.0831e-02, -9.7651e-01, -1.0573e+00],\n",
            "        [-2.1038e+00,  8.6156e-01,  5.2523e-01, -2.4039e-01, -9.4899e-01],\n",
            "        [ 1.3834e+00, -1.7315e-01, -7.7414e-01, -7.4904e-01, -1.1951e-01],\n",
            "        [-3.7604e-01,  1.0271e-01,  3.0386e-01,  2.0764e-01,  1.3654e+00],\n",
            "        [-7.0918e-02, -8.1747e-01,  1.5304e+00, -3.8331e-01,  6.9809e-01],\n",
            "        [ 1.6926e+00, -2.0623e+00,  9.1248e-01, -2.4690e-01, -3.1451e-02],\n",
            "        [-2.8843e-01, -5.9175e-01, -5.5801e-01,  3.3322e-01,  1.0497e+00],\n",
            "        [ 8.2141e-01,  5.5305e-01,  4.2480e-01, -5.0228e-02, -5.2143e-02],\n",
            "        [ 1.7977e+00,  3.8324e-01, -4.7995e-01,  2.4148e-01, -6.8407e-01],\n",
            "        [ 9.7301e-01, -7.0207e-01,  8.0648e-01, -8.7165e-01, -1.0689e+00],\n",
            "        [-6.8406e-01,  7.5376e-02,  8.8201e-03,  3.6999e-01,  2.3761e-01],\n",
            "        [-6.8740e-01,  5.0681e-01,  8.2881e-01, -4.0017e-01,  8.7153e-01],\n",
            "        [ 3.9685e-01, -2.1234e+00, -7.1258e-01,  1.1003e+00,  1.0388e+00],\n",
            "        [ 8.6913e-01,  1.1600e+00,  1.6719e+00,  8.9826e-01,  2.2029e+00],\n",
            "        [-1.3376e+00, -3.0381e+00,  6.4368e-01,  2.6773e+00,  8.3643e-01],\n",
            "        [-7.5735e-01,  9.0440e-01,  1.3806e-01, -2.5022e-02,  2.1111e+00],\n",
            "        [ 4.3827e-01, -1.6450e-01, -6.8864e-01, -1.6572e+00, -1.0708e+00],\n",
            "        [ 2.1443e+00,  1.0384e+00,  7.1000e-01, -1.5215e-01,  5.4470e-01],\n",
            "        [-2.1928e-01, -2.7479e+00, -1.1313e+00,  6.1694e-01, -4.8034e-01],\n",
            "        [-1.8112e+00,  3.5793e-01, -1.1884e+00,  1.4544e+00,  8.5542e-01],\n",
            "        [-9.1880e-01, -1.1440e-01,  8.3725e-01,  4.4116e-02, -1.1909e+00],\n",
            "        [-7.2294e-01, -5.3262e-01,  4.7405e-01, -7.5437e-01,  1.3472e+00],\n",
            "        [-6.5607e-01,  8.5794e-01, -1.0036e+00,  6.3211e-01,  3.2845e-02],\n",
            "        [ 7.0544e-01, -1.1890e-01, -7.2070e-01, -6.5684e-02,  2.5083e-01],\n",
            "        [-2.1681e+00,  1.5268e-01, -1.4686e+00, -7.6969e-01,  1.1971e+00],\n",
            "        [ 6.1956e-01,  3.4479e-01,  5.8346e-02, -6.9056e-02, -1.1491e+00],\n",
            "        [ 8.8379e-01,  2.6405e-01, -3.0297e-01,  2.2006e-01,  2.7467e-01],\n",
            "        [-1.1523e+00, -1.2698e+00, -5.3335e-01,  3.1888e-02,  9.6707e-01],\n",
            "        [ 7.8686e-01,  1.1807e-01, -2.9530e-02, -4.3229e-01, -1.4567e+00],\n",
            "        [-1.2631e+00, -1.7279e-01, -5.3207e-01,  2.8080e+00, -4.3181e-01],\n",
            "        [-2.7375e-01, -7.0802e-01, -5.0991e-01,  6.1205e-01, -6.3177e-01],\n",
            "        [-1.8858e-01,  1.5468e+00,  2.0480e+00, -1.8309e+00, -8.3456e-02],\n",
            "        [ 1.2513e+00, -7.2372e-01, -1.2428e+00, -1.2540e+00, -8.1523e-01],\n",
            "        [ 1.3871e+00, -1.8071e-01, -1.9728e-01,  4.3494e-01, -8.5605e-01],\n",
            "        [-1.7166e+00, -8.7216e-01, -6.8236e-01,  2.0648e-01,  4.0259e-02],\n",
            "        [-1.6384e-01,  1.0618e+00,  7.6577e-01, -8.3577e-01, -1.0090e+00],\n",
            "        [ 2.8831e-01,  1.0984e+00,  1.2822e+00, -1.1692e+00, -8.5458e-01],\n",
            "        [ 2.4191e-01,  1.5491e+00,  1.8488e+00, -7.2992e-02, -1.2365e+00],\n",
            "        [-2.3487e+00, -6.7732e-01, -1.9839e+00,  2.8764e-01, -1.0846e-01]],\n",
            "       requires_grad=True)\n",
            "Content of B1: tensor([[0., 0., 0., 0., 0.]], requires_grad=True)\n",
            "Content of W2: tensor([[-0.1931,  0.2435,  0.3614, -0.7575,  0.1204],\n",
            "        [-0.3685,  0.1989, -1.7422,  1.4666,  0.6065],\n",
            "        [-1.4286,  1.3669,  2.1573,  0.3492, -0.4772],\n",
            "        [-0.7113,  0.8673,  0.6668,  1.0141,  0.3402],\n",
            "        [ 0.4015,  1.0145, -0.1727,  0.3738, -2.6066]], requires_grad=True)\n",
            "Content of B2: tensor([[0., 0., 0., 0., 0.]], requires_grad=True)\n",
            "Content of W3: tensor([[-0.0213],\n",
            "        [ 0.1152],\n",
            "        [ 0.1058],\n",
            "        [ 0.4031],\n",
            "        [ 2.0833]], requires_grad=True)\n",
            "Content of B3: tensor([[0.]], requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "    The data type of X, W1, B1, W2, B2, W3, and B3 is torch.float32. This indicates that the tensors are of type 32-bit floating point.\n",
        "\n",
        "    The content of X is a tensor with a shape that is not visible in the output, but each row appears to have 180 elements. Each element in the tensor is a floating point number.\n",
        "\n",
        "    The content of W1 is a tensor with a shape that is not visible in the output, but each row appears to have 5 elements. Each element in the tensor is a floating point number.\n",
        "\n",
        "    The values of B1, W2, B2, W3, and B3 are not shown in the provided output, but they are of type torch.float32 like the other tensors.\n"
      ],
      "metadata": {
        "id": "Dh2gt-KWmmt6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Minimum value of probs:\", t.min(probs).item())\n",
        "print(\"Maximum value of probs:\", t.max(probs).item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 194
        },
        "id": "4b2VzTM_pnj8",
        "outputId": "0be58860-3766-4e35-d1fe-aea5e0e8afff"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-37-d45f81f0d1d6>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Minimum value of probs:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Maximum value of probs:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'probs' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The error persists even after ensuring that the output of the neural network is bounded by the sigmoid activation function. It seems that the issue might be related to the data input or the way the input data is being processed. Let's check if the data is being processed correctly.\n",
        "\n",
        "One possible reason for this error could be that the data used to compute the loss is not within the expected range of [0, 1]. Please check if the data tensors are of the correct data type and are within the appropriate range. You can also verify the minimum and maximum values of the probs tensor before passing it to the loss function:\n",
        "\n",
        "This will help you determine if the probs tensor contains any values outside the expected range. If the values are outside [0, 1], you might need to revisit the data processing steps or the network architecture to ensure that the outputs are within the appropriate range."
      ],
      "metadata": {
        "id": "G3HFMzmvp6R3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "dMmQ6ojf8_7m"
      },
      "outputs": [],
      "source": [
        "train_loss_list = []\n",
        "\n",
        "# Train the model for a specified number of epochs\n",
        "for epoch in range(epochs):\n",
        "    # Reduce the learning rate every 50 epochs\n",
        "    if epoch % 50 == 0:\n",
        "        learning_rate *= .9\n",
        "\n",
        "    per_epoch_loss_list = []\n",
        "\n",
        "    # Iterate over all batches of data\n",
        "    for batch_idx, (X, Y) in enumerate(train_data_loader):\n",
        "        # Forward pass: Compute predictions\n",
        "        probs = forward(X)\n",
        "\n",
        "        # Compute the loss\n",
        "        loss = loss_fn(probs.view(-1), Y)\n",
        "\n",
        "        # Backward pass: Compute gradient and update weights\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Record the loss for this batch\n",
        "        per_epoch_loss_list.append(loss.item())\n",
        "\n",
        "    # Record the average loss for this epoch\n",
        "    train_loss_list.append(sum(per_epoch_loss_list) / len(per_epoch_loss_list))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 466
        },
        "id": "CymuGs5R9CJ3",
        "outputId": "9b4fb397-47a4-4d1c-bf6f-b730b23672f6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'loss')"
            ]
          },
          "metadata": {},
          "execution_count": 39
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Plot the training loss over epochs\n",
        "plt.plot([i for i in range(len(train_loss_list))], train_loss_list)\n",
        "plt.xlabel('epochs')\n",
        "plt.ylabel('loss')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZwFAwLEb9EUS",
        "outputId": "d8d37653-3814-4a2e-da43-915da9464a8b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.2946301996707916\n",
            "0.293586403131485\n"
          ]
        }
      ],
      "source": [
        "# Evaluate Model Performance on Validation Data\n",
        "\n",
        "# Disable gradient calculations for evaluation using t.no_grad()\n",
        "with t.no_grad():\n",
        "    # Prepare the validation data\n",
        "    X = t.Tensor(X_test).type(t.float32)  # Convert validation features to a PyTorch tensor\n",
        "    Y = t.Tensor(Y_test).type(t.float32)  # Convert validation labels to a PyTorch tensor\n",
        "\n",
        "    # Calculate predictions on the validation data\n",
        "    probs = forward(X)  # Pass validation data through the trained model\n",
        "    loss = loss_fn(probs.view(-1), Y)  # Compute the loss between predictions and actual labels\n",
        "\n",
        "    # Print the validation loss\n",
        "    print(loss.item())\n",
        "\n",
        "    # Now, evaluate the model on the training data\n",
        "    X = t.Tensor(X_train).type(t.float32)  # Convert training features to a PyTorch tensor\n",
        "    Y = t.Tensor(Y_train).type(t.float32)  # Convert training labels to a PyTorch tensor\n",
        "\n",
        "    # Calculate predictions on the training data\n",
        "    probs = forward(X)  # Pass training data through the trained model\n",
        "    loss = loss_fn(probs.view(-1), Y)  # Compute the loss between predictions and actual labels\n",
        "\n",
        "    # Print the training loss\n",
        "    print(loss.item())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t0KgkNl79NIh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d927bc9f-c452-4f00-c11f-ba01805e8150"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0/20 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 1/20 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 2/20 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 3/20 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 4/20 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 5/20 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 6/20 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 7/20 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 8/20 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 9/20 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 10/20 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 11/20 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 12/20 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 13/20 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 14/20 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 15/20 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 16/20 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 17/20 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 18/20 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 19/20 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n"
          ]
        }
      ],
      "source": [
        "number_of_input_features = 177  # Number of input features in the dataset\n",
        "\n",
        "# Reduced number of hidden units to 5 and just using 1 hidden layer\n",
        "number_of_hidden_units = 5  # Number of hidden units in the neural network\n",
        "epochs = 20  # Number of training epochs\n",
        "learning_rate = 0.01  # Learning rate for the optimizer\n",
        "batch_size = 32  # Number of samples in each training batch\n",
        "dropout_probablity = 0.6  # Probability of dropping out a neuron in dropout layer\n",
        "\n",
        "# Convert training and testing data to PyTorch tensors\n",
        "X_train_tensor = t.Tensor(X_train).type(t.float32)\n",
        "Y_train_tensor = t.Tensor(Y_train).type(t.float32)\n",
        "X_test_tensor = t.Tensor(X_test).type(t.float32)\n",
        "Y_test_tensor = t.Tensor(Y_test).type(t.float32)\n",
        "\n",
        "# Create a training dataset and data loader\n",
        "train_dataset = TensorDataset(X_train_tensor, Y_train_tensor)\n",
        "train_data_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "# Define the neural network model\n",
        "model = Sequential(\n",
        "    Linear(number_of_input_features, number_of_hidden_units),  # Linear layer for matrix multiplication and bias addition\n",
        "    Tanh(),  # Add Tanh activation function\n",
        "    Dropout(dropout_probablity),  # Dropout layer to prevent overfitting\n",
        "    Linear(number_of_hidden_units, 1),  # Another linear layer\n",
        "    Sigmoid()  # Sigmoid activation for probability output\n",
        ")\n",
        "\n",
        "# Define the optimizer\n",
        "optimizer = Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# Define the loss function as Binary Cross-Entropy Loss\n",
        "loss_fn = t.nn.BCELoss()\n",
        "\n",
        "train_accuracy_list = []  # List to store training accuracy\n",
        "validation_accuracy_list = []  # List to store validation accuracy\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(epochs):\n",
        "    if epoch % 20 == 0:\n",
        "        learning_rate *= 0.9  # Learning rate scheduling\n",
        "\n",
        "    per_epoch_loss_list = []  # List to store losses for each epoch\n",
        "\n",
        "    for batch_idx, (X, Y) in enumerate(train_data_loader):\n",
        "        # Forward pass: Compute predictions\n",
        "        probs = model(X)\n",
        "\n",
        "        # Calculate the loss\n",
        "        loss = loss_fn(probs.view(-1), Y)\n",
        "        per_epoch_loss_list.append(loss.item())\n",
        "\n",
        "        # Backward pass: Compute gradients and update weights\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    # Evaluate the model on training and validation data\n",
        "    with t.no_grad():\n",
        "        # Set the model in eval mode; some layers use this for certain calculations during training\n",
        "        model.eval()\n",
        "\n",
        "        # Calculate accuracy on train data\n",
        "        probs = model(X_train_tensor)\n",
        "        prediction = (probs >= 0.5).type(t.LongTensor).view(-1)\n",
        "        train_accuracy = (prediction == Y_train_tensor).type(t.float32).mean().item()\n",
        "\n",
        "        # Calculate accuracy on validation data\n",
        "        probs = model(X_test_tensor)\n",
        "        prediction = (probs >= 0.5).type(t.LongTensor).view(-1)\n",
        "        validation_accuracy = (prediction == Y_test_tensor).type(t.float32).mean().item()\n",
        "\n",
        "        print(f'epoch {epoch}/{epochs} ---> train_accuracy: {train_accuracy}, validation_accuracy: {validation_accuracy}')\n",
        "\n",
        "        # Set the model back to train mode\n",
        "        model.train()\n",
        "\n",
        "        # Append accuracy values to lists\n",
        "        train_accuracy_list.append(train_accuracy)\n",
        "        validation_accuracy_list.append(validation_accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch as t\n",
        "import torch.nn as nn\n",
        "from torch.optim import Adam\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Regularization\n",
        "# Deep neural networks are prone to overfitting if there is not much data available during training.\n",
        "\n",
        "# Define hyperparameters\n",
        "number_of_input_features = 177\n",
        "number_of_hidden_units = 5\n",
        "epochs = 100\n",
        "learning_rate = 0.01\n",
        "batch_size = 32\n",
        "landa = 0.01  # Regularization term (lambda)\n",
        "\n",
        "# Prepare the data\n",
        "X_train_tensor = t.Tensor(X_train).type(t.float32)\n",
        "Y_train_tensor = t.Tensor(Y_train).type(t.float32)\n",
        "\n",
        "X_test_tensor = t.Tensor(X_test).type(t.float32)\n",
        "Y_test_tensor = t.Tensor(Y_test).type(t.float32)\n",
        "\n",
        "train_dataset = TensorDataset(X_train_tensor, Y_train_tensor)\n",
        "train_data_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "# Define the neural network model with regularization\n",
        "model = nn.Sequential(\n",
        "    nn.Linear(number_of_input_features, number_of_hidden_units),  # Linear layer for matrix multiplication and bias addition\n",
        "    nn.Tanh(),  # Tanh activation function\n",
        "    nn.Linear(number_of_hidden_units, 1),  # Another linear layer\n",
        "    nn.Sigmoid()  # Sigmoid activation for probability output\n",
        ")\n",
        "\n",
        "# Define the optimizer\n",
        "optimizer = Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# Define the loss function with Binary Cross-Entropy Loss\n",
        "loss_fn = nn.BCELoss()\n",
        "\n",
        "# Lists to store training accuracy, validation accuracy, and training loss over epochs\n",
        "train_accuracy_list = []\n",
        "validation_accuracy_list = []\n",
        "train_loss_list = []\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    if epoch % 500 == 0:\n",
        "        learning_rate *= 0.9  # Learning rate scheduling\n",
        "\n",
        "    per_epoch_loss_list = []\n",
        "\n",
        "    for batch_idx, (X, Y) in enumerate(train_data_loader):\n",
        "        # Forward pass: Compute predictions\n",
        "        probs = model(X)\n",
        "\n",
        "        # Adding regularization term for all parameters in the model\n",
        "        l2_term = sum([(w ** 2).sum() for w in model.parameters()])\n",
        "\n",
        "        # New loss is the old loss + regularization term\n",
        "        loss = loss_fn(probs.view(-1), Y) + landa * l2_term\n",
        "\n",
        "        per_epoch_loss_list.append(loss.item())\n",
        "\n",
        "        # Backward pass: Compute gradient and update weights\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    # Evaluate the model on training and validation data\n",
        "    with t.no_grad():\n",
        "        # Set the model in eval mode; some layers use this for certain calculations during training\n",
        "        model.eval()\n",
        "\n",
        "        # Calculate accuracy on train data\n",
        "        probs = model(X_train_tensor)\n",
        "        prediction = (probs >= 0.5).type(t.LongTensor).view(-1)\n",
        "        train_accuracy = (prediction == Y_train_tensor).type(t.float32).mean().item()\n",
        "\n",
        "        # Calculate accuracy on validation data\n",
        "        probs = model(X_test_tensor)\n",
        "        prediction = (probs >= 0.5).type(t.LongTensor).view(-1)\n",
        "        validation_accuracy = (prediction == Y_test_tensor).type(t.float32).mean().item()\n",
        "\n",
        "        # Print accuracy for the current epoch\n",
        "        print(f'Epoch {epoch}/{epochs} ---> Train Accuracy: {train_accuracy}, Validation Accuracy: {validation_accuracy}')\n",
        "\n",
        "        # Set the model back to train mode\n",
        "        model.train()\n",
        "\n",
        "        # Append accuracy values to lists\n",
        "        train_accuracy_list.append(train_accuracy)\n",
        "        validation_accuracy_list.append(validation_accuracy)\n",
        "\n",
        "    # Calculate and append the average loss for the epoch\n",
        "    train_loss_list.append(sum(per_epoch_loss_list) / len(per_epoch_loss_list))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c22bccm02LyC",
        "outputId": "0cd05f8f-a97b-4365-e46f-c35ab18ca056"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0/100 ---> Train Accuracy: 0.9138304591178894, Validation Accuracy: 0.9133895635604858\n",
            "Epoch 1/100 ---> Train Accuracy: 0.9138304591178894, Validation Accuracy: 0.9133895635604858\n",
            "Epoch 2/100 ---> Train Accuracy: 0.9138304591178894, Validation Accuracy: 0.9133895635604858\n",
            "Epoch 3/100 ---> Train Accuracy: 0.9138304591178894, Validation Accuracy: 0.9133895635604858\n",
            "Epoch 4/100 ---> Train Accuracy: 0.9138304591178894, Validation Accuracy: 0.9133895635604858\n",
            "Epoch 5/100 ---> Train Accuracy: 0.9138304591178894, Validation Accuracy: 0.9133895635604858\n",
            "Epoch 6/100 ---> Train Accuracy: 0.9138304591178894, Validation Accuracy: 0.9133895635604858\n",
            "Epoch 7/100 ---> Train Accuracy: 0.9138304591178894, Validation Accuracy: 0.9133895635604858\n",
            "Epoch 8/100 ---> Train Accuracy: 0.9138304591178894, Validation Accuracy: 0.9133895635604858\n",
            "Epoch 9/100 ---> Train Accuracy: 0.9138304591178894, Validation Accuracy: 0.9133895635604858\n",
            "Epoch 10/100 ---> Train Accuracy: 0.9138304591178894, Validation Accuracy: 0.9133895635604858\n",
            "Epoch 11/100 ---> Train Accuracy: 0.9138304591178894, Validation Accuracy: 0.9133895635604858\n",
            "Epoch 12/100 ---> Train Accuracy: 0.9138304591178894, Validation Accuracy: 0.9133895635604858\n",
            "Epoch 13/100 ---> Train Accuracy: 0.9138304591178894, Validation Accuracy: 0.9133895635604858\n",
            "Epoch 14/100 ---> Train Accuracy: 0.9138304591178894, Validation Accuracy: 0.9133895635604858\n",
            "Epoch 15/100 ---> Train Accuracy: 0.9138304591178894, Validation Accuracy: 0.9133895635604858\n",
            "Epoch 16/100 ---> Train Accuracy: 0.9138304591178894, Validation Accuracy: 0.9133895635604858\n",
            "Epoch 17/100 ---> Train Accuracy: 0.9138304591178894, Validation Accuracy: 0.9133895635604858\n",
            "Epoch 18/100 ---> Train Accuracy: 0.9138304591178894, Validation Accuracy: 0.9133895635604858\n",
            "Epoch 19/100 ---> Train Accuracy: 0.9138304591178894, Validation Accuracy: 0.9133895635604858\n",
            "Epoch 20/100 ---> Train Accuracy: 0.9138304591178894, Validation Accuracy: 0.9133895635604858\n",
            "Epoch 21/100 ---> Train Accuracy: 0.9138304591178894, Validation Accuracy: 0.9133895635604858\n",
            "Epoch 22/100 ---> Train Accuracy: 0.9138304591178894, Validation Accuracy: 0.9133895635604858\n",
            "Epoch 23/100 ---> Train Accuracy: 0.9138304591178894, Validation Accuracy: 0.9133895635604858\n",
            "Epoch 24/100 ---> Train Accuracy: 0.9138304591178894, Validation Accuracy: 0.9133895635604858\n",
            "Epoch 25/100 ---> Train Accuracy: 0.9138304591178894, Validation Accuracy: 0.9133895635604858\n",
            "Epoch 26/100 ---> Train Accuracy: 0.9138304591178894, Validation Accuracy: 0.9133895635604858\n",
            "Epoch 27/100 ---> Train Accuracy: 0.9138304591178894, Validation Accuracy: 0.9133895635604858\n",
            "Epoch 28/100 ---> Train Accuracy: 0.9138304591178894, Validation Accuracy: 0.9133895635604858\n",
            "Epoch 29/100 ---> Train Accuracy: 0.9138304591178894, Validation Accuracy: 0.9133895635604858\n",
            "Epoch 30/100 ---> Train Accuracy: 0.9138304591178894, Validation Accuracy: 0.9133895635604858\n",
            "Epoch 31/100 ---> Train Accuracy: 0.9138304591178894, Validation Accuracy: 0.9133895635604858\n",
            "Epoch 32/100 ---> Train Accuracy: 0.9138304591178894, Validation Accuracy: 0.9133895635604858\n",
            "Epoch 33/100 ---> Train Accuracy: 0.9138304591178894, Validation Accuracy: 0.9133895635604858\n",
            "Epoch 34/100 ---> Train Accuracy: 0.9138304591178894, Validation Accuracy: 0.9133895635604858\n",
            "Epoch 35/100 ---> Train Accuracy: 0.9138304591178894, Validation Accuracy: 0.9133895635604858\n",
            "Epoch 36/100 ---> Train Accuracy: 0.9138304591178894, Validation Accuracy: 0.9133895635604858\n",
            "Epoch 37/100 ---> Train Accuracy: 0.9138304591178894, Validation Accuracy: 0.9133895635604858\n",
            "Epoch 38/100 ---> Train Accuracy: 0.9138304591178894, Validation Accuracy: 0.9133895635604858\n",
            "Epoch 39/100 ---> Train Accuracy: 0.9138304591178894, Validation Accuracy: 0.9133895635604858\n",
            "Epoch 40/100 ---> Train Accuracy: 0.9138304591178894, Validation Accuracy: 0.9133895635604858\n",
            "Epoch 41/100 ---> Train Accuracy: 0.9138304591178894, Validation Accuracy: 0.9133895635604858\n",
            "Epoch 42/100 ---> Train Accuracy: 0.9138304591178894, Validation Accuracy: 0.9133895635604858\n",
            "Epoch 43/100 ---> Train Accuracy: 0.9138304591178894, Validation Accuracy: 0.9133895635604858\n",
            "Epoch 44/100 ---> Train Accuracy: 0.9138304591178894, Validation Accuracy: 0.9133895635604858\n",
            "Epoch 45/100 ---> Train Accuracy: 0.9138304591178894, Validation Accuracy: 0.9133895635604858\n",
            "Epoch 46/100 ---> Train Accuracy: 0.9138304591178894, Validation Accuracy: 0.9133895635604858\n",
            "Epoch 47/100 ---> Train Accuracy: 0.9138304591178894, Validation Accuracy: 0.9133895635604858\n",
            "Epoch 48/100 ---> Train Accuracy: 0.9138304591178894, Validation Accuracy: 0.9133895635604858\n",
            "Epoch 49/100 ---> Train Accuracy: 0.9138304591178894, Validation Accuracy: 0.9133895635604858\n",
            "Epoch 50/100 ---> Train Accuracy: 0.9138304591178894, Validation Accuracy: 0.9133895635604858\n",
            "Epoch 51/100 ---> Train Accuracy: 0.9138304591178894, Validation Accuracy: 0.9133895635604858\n",
            "Epoch 52/100 ---> Train Accuracy: 0.9138304591178894, Validation Accuracy: 0.9133895635604858\n",
            "Epoch 53/100 ---> Train Accuracy: 0.9138304591178894, Validation Accuracy: 0.9133895635604858\n",
            "Epoch 54/100 ---> Train Accuracy: 0.9138304591178894, Validation Accuracy: 0.9133895635604858\n",
            "Epoch 55/100 ---> Train Accuracy: 0.9138304591178894, Validation Accuracy: 0.9133895635604858\n",
            "Epoch 56/100 ---> Train Accuracy: 0.9138304591178894, Validation Accuracy: 0.9133895635604858\n",
            "Epoch 57/100 ---> Train Accuracy: 0.9138304591178894, Validation Accuracy: 0.9133895635604858\n",
            "Epoch 58/100 ---> Train Accuracy: 0.9138304591178894, Validation Accuracy: 0.9133895635604858\n",
            "Epoch 59/100 ---> Train Accuracy: 0.9138304591178894, Validation Accuracy: 0.9133895635604858\n",
            "Epoch 60/100 ---> Train Accuracy: 0.9138304591178894, Validation Accuracy: 0.9133895635604858\n",
            "Epoch 61/100 ---> Train Accuracy: 0.9138304591178894, Validation Accuracy: 0.9133895635604858\n",
            "Epoch 62/100 ---> Train Accuracy: 0.9138304591178894, Validation Accuracy: 0.9133895635604858\n",
            "Epoch 63/100 ---> Train Accuracy: 0.9138304591178894, Validation Accuracy: 0.9133895635604858\n",
            "Epoch 64/100 ---> Train Accuracy: 0.9138304591178894, Validation Accuracy: 0.9133895635604858\n",
            "Epoch 65/100 ---> Train Accuracy: 0.9138304591178894, Validation Accuracy: 0.9133895635604858\n",
            "Epoch 66/100 ---> Train Accuracy: 0.9138304591178894, Validation Accuracy: 0.9133895635604858\n",
            "Epoch 67/100 ---> Train Accuracy: 0.9138304591178894, Validation Accuracy: 0.9133895635604858\n",
            "Epoch 68/100 ---> Train Accuracy: 0.9138304591178894, Validation Accuracy: 0.9133895635604858\n",
            "Epoch 69/100 ---> Train Accuracy: 0.9138304591178894, Validation Accuracy: 0.9133895635604858\n",
            "Epoch 70/100 ---> Train Accuracy: 0.9138304591178894, Validation Accuracy: 0.9133895635604858\n",
            "Epoch 71/100 ---> Train Accuracy: 0.9138304591178894, Validation Accuracy: 0.9133895635604858\n",
            "Epoch 72/100 ---> Train Accuracy: 0.9138304591178894, Validation Accuracy: 0.9133895635604858\n",
            "Epoch 73/100 ---> Train Accuracy: 0.9138304591178894, Validation Accuracy: 0.9133895635604858\n",
            "Epoch 74/100 ---> Train Accuracy: 0.9138304591178894, Validation Accuracy: 0.9133895635604858\n",
            "Epoch 75/100 ---> Train Accuracy: 0.9138304591178894, Validation Accuracy: 0.9133895635604858\n",
            "Epoch 76/100 ---> Train Accuracy: 0.9138304591178894, Validation Accuracy: 0.9133895635604858\n",
            "Epoch 77/100 ---> Train Accuracy: 0.9138304591178894, Validation Accuracy: 0.9133895635604858\n",
            "Epoch 78/100 ---> Train Accuracy: 0.9138304591178894, Validation Accuracy: 0.9133895635604858\n",
            "Epoch 79/100 ---> Train Accuracy: 0.9138304591178894, Validation Accuracy: 0.9133895635604858\n",
            "Epoch 80/100 ---> Train Accuracy: 0.9138304591178894, Validation Accuracy: 0.9133895635604858\n",
            "Epoch 81/100 ---> Train Accuracy: 0.9138304591178894, Validation Accuracy: 0.9133895635604858\n",
            "Epoch 82/100 ---> Train Accuracy: 0.9138304591178894, Validation Accuracy: 0.9133895635604858\n",
            "Epoch 83/100 ---> Train Accuracy: 0.9138304591178894, Validation Accuracy: 0.9133895635604858\n",
            "Epoch 84/100 ---> Train Accuracy: 0.9138304591178894, Validation Accuracy: 0.9133895635604858\n",
            "Epoch 85/100 ---> Train Accuracy: 0.9138304591178894, Validation Accuracy: 0.9133895635604858\n",
            "Epoch 86/100 ---> Train Accuracy: 0.9138304591178894, Validation Accuracy: 0.9133895635604858\n",
            "Epoch 87/100 ---> Train Accuracy: 0.9138304591178894, Validation Accuracy: 0.9133895635604858\n",
            "Epoch 88/100 ---> Train Accuracy: 0.9138304591178894, Validation Accuracy: 0.9133895635604858\n",
            "Epoch 89/100 ---> Train Accuracy: 0.9138304591178894, Validation Accuracy: 0.9133895635604858\n",
            "Epoch 90/100 ---> Train Accuracy: 0.9138304591178894, Validation Accuracy: 0.9133895635604858\n",
            "Epoch 91/100 ---> Train Accuracy: 0.9138304591178894, Validation Accuracy: 0.9133895635604858\n",
            "Epoch 92/100 ---> Train Accuracy: 0.9138304591178894, Validation Accuracy: 0.9133895635604858\n",
            "Epoch 93/100 ---> Train Accuracy: 0.9138304591178894, Validation Accuracy: 0.9133895635604858\n",
            "Epoch 94/100 ---> Train Accuracy: 0.9138304591178894, Validation Accuracy: 0.9133895635604858\n",
            "Epoch 95/100 ---> Train Accuracy: 0.9138304591178894, Validation Accuracy: 0.9133895635604858\n",
            "Epoch 96/100 ---> Train Accuracy: 0.9138304591178894, Validation Accuracy: 0.9133895635604858\n",
            "Epoch 97/100 ---> Train Accuracy: 0.9138304591178894, Validation Accuracy: 0.9133895635604858\n",
            "Epoch 98/100 ---> Train Accuracy: 0.9138304591178894, Validation Accuracy: 0.9133895635604858\n",
            "Epoch 99/100 ---> Train Accuracy: 0.9138304591178894, Validation Accuracy: 0.9133895635604858\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot training and validation accuracy over epochs\n",
        "plt.plot([i for i in range(len(train_accuracy_list))], train_accuracy_list, label=\"Train\")\n",
        "plt.plot([i for i in range(len(validation_accuracy_list))], validation_accuracy_list, label=\"Validation\")\n",
        "plt.legend(loc=\"upper left\")\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "id": "CsU7iF4G4CQW",
        "outputId": "b135091d-0a47-4af2-de43-2b78b5c208cf"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Dropout as a form of regularization to prevent overfitting\n",
        "number_of_input_features = 177  # Number of input features in the dataset\n",
        "\n",
        "# Reduced number of hidden units to 5 and just using 1 hidden layer\n",
        "number_of_hidden_units = 5  # Number of hidden units in the neural network\n",
        "epochs = 500  # Number of training epochs\n",
        "learning_rate = 0.01  # Learning rate for the optimizer\n",
        "batch_size = 32  # Number of samples in each training batch\n",
        "dropout_probablity = 0.6  # Probability of dropping out a neuron in dropout layer\n",
        "\n",
        "# Convert training and testing data to PyTorch tensors\n",
        "X_train_tensor = t.Tensor(X_train).type(t.float32)\n",
        "Y_train_tensor = t.Tensor(Y_train).type(t.float32)\n",
        "X_test_tensor = t.Tensor(X_test).type(t.float32)\n",
        "Y_test_tensor = t.Tensor(Y_test).type(t.float32)\n",
        "\n",
        "# Create a training dataset and data loader\n",
        "train_dataset = TensorDataset(X_train_tensor, Y_train_tensor)\n",
        "train_data_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "# Define the neural network model\n",
        "model = Sequential(\n",
        "    Linear(number_of_input_features, number_of_hidden_units),  # Linear layer for matrix multiplication and bias addition\n",
        "    Tanh(),  # Add Tanh activation function\n",
        "    Dropout(dropout_probablity),  # Dropout layer to prevent overfitting\n",
        "    Linear(number_of_hidden_units, 1),  # Another linear layer\n",
        "    Sigmoid()  # Sigmoid activation for probability output\n",
        ")\n",
        "\n",
        "# Define the optimizer\n",
        "optimizer = Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# Define the loss function as Binary Cross-Entropy Loss\n",
        "loss_fn = t.nn.BCELoss()\n",
        "\n",
        "train_accuracy_list = []  # List to store training accuracy\n",
        "validation_accuracy_list = []  # List to store validation accuracy\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(epochs):\n",
        "    if epoch % 500 == 0:\n",
        "        learning_rate *= 0.9  # Learning rate scheduling\n",
        "\n",
        "    per_epoch_loss_list = []  # List to store losses for each epoch\n",
        "\n",
        "    for batch_idx, (X, Y) in enumerate(train_data_loader):\n",
        "        # Forward pass: Compute predictions\n",
        "        probs = model(X)\n",
        "\n",
        "        # Calculate the loss\n",
        "        loss = loss_fn(probs.view(-1), Y)\n",
        "        per_epoch_loss_list.append(loss.item())\n",
        "\n",
        "        # Backward pass: Compute gradients and update weights\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    # Evaluate the model on training and validation data\n",
        "    with t.no_grad():\n",
        "        # Set the model in eval mode; some layers use this for certain calculations during training\n",
        "        model.eval()\n",
        "\n",
        "        # Calculate accuracy on train data\n",
        "        probs = model(X_train_tensor)\n",
        "        prediction = (probs >= 0.5).type(t.LongTensor).view(-1)\n",
        "        train_accuracy = (prediction == Y_train_tensor).type(t.float32).mean().item()\n",
        "\n",
        "        # Calculate accuracy on validation data\n",
        "        probs = model(X_test_tensor)\n",
        "        prediction = (probs >= 0.5).type(t.LongTensor).view(-1)\n",
        "        validation_accuracy = (prediction == Y_test_tensor).type(t.float32).mean().item()\n",
        "\n",
        "        print(f'epoch {epoch}/{epochs} ---> train_accuracy: {train_accuracy}, validation_accuracy: {validation_accuracy}')\n",
        "\n",
        "        # Set the model back to train mode\n",
        "        model.train()\n",
        "\n",
        "        # Append accuracy values to lists\n",
        "        train_accuracy_list.append(train_accuracy)\n",
        "        validation_accuracy_list.append(validation_accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mFCw811b4MNo",
        "outputId": "1bc49b43-95b2-499b-dd63-aeafd431ca16"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 1/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 2/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 3/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 4/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 5/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 6/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 7/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 8/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 9/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 10/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 11/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 12/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 13/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 14/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 15/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 16/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 17/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 18/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 19/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 20/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 21/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 22/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 23/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 24/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 25/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 26/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 27/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 28/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 29/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 30/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 31/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 32/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 33/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 34/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 35/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 36/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 37/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 38/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 39/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 40/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 41/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 42/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 43/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 44/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 45/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 46/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 47/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 48/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 49/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 50/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 51/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 52/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 53/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 54/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 55/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 56/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 57/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 58/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 59/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 60/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 61/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 62/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 63/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 64/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 65/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 66/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 67/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 68/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 69/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 70/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 71/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 72/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 73/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 74/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 75/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 76/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 77/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 78/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 79/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 80/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 81/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 82/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 83/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 84/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 85/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 86/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 87/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 88/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 89/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 90/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 91/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 92/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 93/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 94/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 95/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 96/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 97/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 98/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 99/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 100/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 101/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 102/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 103/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 104/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 105/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 106/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 107/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 108/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 109/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 110/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 111/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 112/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 113/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 114/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 115/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 116/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 117/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 118/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 119/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 120/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 121/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 122/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 123/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 124/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 125/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 126/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 127/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 128/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 129/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 130/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 131/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 132/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 133/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 134/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 135/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 136/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 137/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 138/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 139/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 140/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 141/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 142/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 143/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 144/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 145/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 146/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 147/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 148/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 149/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 150/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 151/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 152/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 153/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 154/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 155/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 156/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 157/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 158/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 159/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 160/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 161/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 162/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 163/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 164/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 165/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 166/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 167/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 168/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 169/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 170/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 171/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 172/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 173/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 174/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 175/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 176/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 177/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 178/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 179/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 180/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 181/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 182/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 183/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 184/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 185/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 186/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 187/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 188/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 189/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 190/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 191/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 192/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 193/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 194/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 195/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 196/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 197/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 198/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 199/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 200/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 201/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 202/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 203/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 204/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 205/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 206/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 207/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 208/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 209/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 210/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 211/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 212/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 213/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 214/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 215/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 216/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 217/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 218/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 219/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 220/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 221/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 222/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 223/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 224/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 225/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 226/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 227/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 228/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 229/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 230/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 231/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 232/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 233/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 234/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 235/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 236/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 237/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 238/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 239/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 240/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 241/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 242/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 243/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 244/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 245/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 246/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 247/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 248/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 249/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 250/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 251/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 252/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 253/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 254/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 255/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 256/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 257/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 258/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 259/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 260/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 261/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 262/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 263/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 264/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 265/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 266/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 267/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 268/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 269/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 270/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 271/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 272/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 273/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 274/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 275/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 276/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 277/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 278/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 279/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 280/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 281/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 282/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 283/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 284/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 285/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 286/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 287/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 288/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 289/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 290/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 291/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 292/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 293/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 294/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 295/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 296/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 297/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 298/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 299/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 300/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 301/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 302/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 303/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 304/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 305/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 306/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 307/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 308/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 309/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 310/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 311/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 312/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 313/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 314/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 315/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 316/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 317/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 318/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 319/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 320/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 321/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 322/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 323/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 324/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 325/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 326/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 327/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 328/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 329/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 330/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 331/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 332/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 333/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 334/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 335/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 336/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 337/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 338/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 339/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 340/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 341/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 342/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 343/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 344/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 345/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 346/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 347/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 348/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 349/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 350/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 351/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 352/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 353/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 354/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 355/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 356/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 357/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 358/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 359/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 360/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 361/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 362/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 363/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 364/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 365/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 366/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 367/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 368/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 369/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 370/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 371/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 372/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 373/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 374/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 375/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 376/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 377/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 378/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 379/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 380/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 381/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 382/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 383/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 384/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 385/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 386/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 387/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 388/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 389/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 390/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 391/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 392/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 393/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 394/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 395/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 396/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 397/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 398/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 399/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 400/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 401/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 402/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 403/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 404/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 405/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 406/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 407/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 408/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 409/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 410/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 411/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 412/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 413/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 414/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 415/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 416/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 417/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 418/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 419/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 420/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 421/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 422/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 423/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 424/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 425/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 426/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 427/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 428/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 429/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 430/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 431/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 432/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 433/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 434/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 435/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 436/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 437/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 438/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 439/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 440/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 441/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 442/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 443/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 444/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 445/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 446/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 447/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 448/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 449/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 450/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 451/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 452/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 453/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 454/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 455/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 456/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 457/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 458/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 459/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 460/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 461/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 462/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 463/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 464/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 465/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 466/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 467/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 468/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 469/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 470/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 471/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 472/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 473/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 474/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 475/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 476/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 477/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 478/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 479/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 480/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 481/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 482/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 483/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 484/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 485/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 486/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 487/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 488/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 489/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 490/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 491/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 492/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 493/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 494/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 495/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 496/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 497/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 498/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n",
            "epoch 499/500 ---> train_accuracy: 0.9138304591178894, validation_accuracy: 0.9133895635604858\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot training and validation accuracy over epochs\n",
        "plt.plot([i for i in range(len(train_accuracy_list))], train_accuracy_list, label=\"train\")\n",
        "plt.plot([i for i in range(len(validation_accuracy_list))], validation_accuracy_list, label=\"validation\")\n",
        "plt.legend(loc=\"upper left\")\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('accuracy')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 466
        },
        "id": "UxJ8rbuEAUvD",
        "outputId": "dfda8a3d-e5a6-4317-e333-959721dbd680"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'accuracy')"
            ]
          },
          "metadata": {},
          "execution_count": 46
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Halting Overfitting\n",
        "# Importing necessary libraries\n",
        "import torch as t\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "from torch.nn import Sequential, Linear, Tanh, Sigmoid\n",
        "from torch.optim import Adam\n",
        "from torch.nn import BCELoss\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Defining the parameters\n",
        "number_of_input_features = 177\n",
        "number_of_hidden_units = 5\n",
        "epochs = 1000\n",
        "learning_rate = 0.01\n",
        "batch_size = 32\n",
        "\n",
        "# Loading and preprocessing the data\n",
        "X_train_tensor = t.Tensor(X_train).type(t.float32)\n",
        "Y_train_tensor = t.Tensor(Y_train).type(t.float32)\n",
        "\n",
        "X_test_tensor = t.Tensor(X_test).type(t.float32)\n",
        "Y_test_tensor = t.Tensor(Y_test).type(t.float32)\n",
        "\n",
        "train_dataset = TensorDataset(X_train_tensor, Y_train_tensor)\n",
        "train_data_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "# Creating a neural network model\n",
        "model = Sequential(\n",
        "    Linear(number_of_input_features, number_of_hidden_units),\n",
        "    Tanh(),\n",
        "    Linear(number_of_hidden_units, 1),\n",
        "    Sigmoid()\n",
        ")\n",
        "\n",
        "# Setting up the optimizer and loss function\n",
        "optimizer = Adam(model.parameters(), lr=learning_rate)\n",
        "loss_fn = BCELoss()\n",
        "\n",
        "# Lists to store accuracy values during training\n",
        "train_accuracy_list = []\n",
        "validation_accuracy_list = []\n",
        "\n",
        "# Main training loop\n",
        "for epoch in range(epochs):\n",
        "    # Learning rate scheduling (optional)\n",
        "    if epoch % 500 == 0:\n",
        "        learning_rate *= .9\n",
        "\n",
        "    per_epoch_loss_list = []\n",
        "\n",
        "    for batch_idx, (X, Y) in enumerate(train_data_loader):\n",
        "        probs = model(X)\n",
        "\n",
        "        # new loss is the old loss + regularization term\n",
        "        loss = loss_fn(probs.view(-1), Y)\n",
        "\n",
        "        per_epoch_loss_list.append(loss.item())\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    with t.no_grad():\n",
        "        # Calculate accuracy on train data\n",
        "        model.eval()\n",
        "        probs = model(X_train_tensor)\n",
        "        prediction = (probs >= .5).type(t.LongTensor).view(-1)\n",
        "\n",
        "        train_accuracy = (prediction == Y_train_tensor).type(t.float32).mean().item()\n",
        "\n",
        "        # Calculate accuracy on validation data\n",
        "        probs = model(X_test_tensor)\n",
        "        prediction = (probs > .5).type(t.LongTensor).view(-1)\n",
        "\n",
        "        validation_accuracy = (prediction == Y_test_tensor).type(t.float32).mean().item()\n",
        "\n",
        "        print(f'epoch {epoch}/{epochs} ---> train_accuracy : {train_accuracy} , validation_accuracy : {validation_accuracy}')\n",
        "        model.train()\n",
        "        train_accuracy_list.append(train_accuracy)\n",
        "        validation_accuracy_list.append(validation_accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "De5Qv4CDAZ7z",
        "outputId": "0d24bc56-a185-4d6f-c971-c591237dff21"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 1/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 2/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 3/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 4/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 5/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 6/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 7/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 8/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 9/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 10/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 11/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 12/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 13/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 14/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 15/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 16/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 17/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 18/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 19/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 20/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 21/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 22/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 23/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 24/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 25/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 26/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 27/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 28/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 29/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 30/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 31/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 32/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 33/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 34/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 35/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 36/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 37/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 38/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 39/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 40/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 41/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 42/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 43/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 44/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 45/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 46/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 47/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 48/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 49/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 50/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 51/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 52/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 53/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 54/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 55/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 56/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 57/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 58/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 59/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 60/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 61/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 62/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 63/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 64/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 65/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 66/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 67/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 68/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 69/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 70/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 71/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 72/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 73/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 74/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 75/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 76/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 77/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 78/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 79/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 80/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 81/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 82/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 83/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 84/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 85/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 86/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 87/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 88/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 89/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 90/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 91/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 92/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 93/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 94/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 95/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 96/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 97/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 98/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 99/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 100/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 101/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 102/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 103/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 104/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 105/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 106/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 107/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 108/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 109/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 110/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 111/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 112/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 113/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 114/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 115/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 116/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 117/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 118/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 119/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 120/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 121/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 122/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 123/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 124/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 125/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 126/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 127/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 128/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 129/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 130/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 131/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 132/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 133/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 134/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 135/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 136/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 137/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 138/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 139/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 140/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 141/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 142/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 143/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 144/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 145/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 146/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 147/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 148/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 149/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 150/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 151/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 152/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 153/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 154/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 155/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 156/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 157/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 158/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 159/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 160/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 161/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 162/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 163/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 164/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 165/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 166/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 167/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 168/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 169/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 170/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 171/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 172/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 173/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 174/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 175/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 176/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 177/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 178/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 179/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 180/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 181/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 182/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 183/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 184/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 185/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 186/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 187/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 188/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 189/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 190/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 191/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 192/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 193/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 194/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 195/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 196/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 197/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 198/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 199/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 200/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 201/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 202/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 203/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 204/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 205/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 206/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 207/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 208/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 209/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 210/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 211/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 212/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 213/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 214/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 215/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 216/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 217/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 218/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 219/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 220/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 221/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 222/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 223/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 224/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 225/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 226/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 227/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 228/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 229/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 230/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 231/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 232/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 233/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 234/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 235/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 236/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 237/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 238/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 239/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 240/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 241/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 242/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 243/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 244/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 245/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 246/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 247/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 248/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 249/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 250/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 251/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 252/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 253/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 254/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 255/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 256/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 257/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 258/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 259/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 260/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 261/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 262/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 263/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 264/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 265/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 266/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 267/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 268/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 269/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 270/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 271/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 272/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 273/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 274/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 275/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 276/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 277/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 278/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 279/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 280/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 281/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 282/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 283/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 284/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 285/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 286/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 287/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 288/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 289/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 290/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 291/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 292/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 293/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 294/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 295/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 296/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 297/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 298/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 299/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 300/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 301/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 302/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 303/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 304/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 305/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 306/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 307/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 308/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 309/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 310/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 311/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 312/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 313/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 314/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 315/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 316/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 317/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 318/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 319/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 320/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 321/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 322/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 323/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 324/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 325/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 326/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 327/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 328/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 329/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 330/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 331/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 332/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 333/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 334/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 335/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 336/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 337/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 338/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 339/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 340/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 341/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 342/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 343/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 344/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 345/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 346/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 347/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 348/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 349/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 350/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 351/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 352/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 353/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 354/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 355/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 356/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 357/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 358/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 359/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 360/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 361/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 362/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 363/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 364/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 365/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 366/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 367/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 368/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 369/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 370/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 371/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 372/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 373/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 374/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 375/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 376/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 377/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 378/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 379/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 380/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 381/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 382/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 383/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 384/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 385/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 386/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 387/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 388/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 389/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 390/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 391/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 392/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 393/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 394/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 395/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 396/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 397/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 398/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 399/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 400/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 401/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 402/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 403/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 404/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 405/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 406/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 407/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 408/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 409/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 410/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 411/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 412/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 413/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 414/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 415/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 416/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 417/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 418/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 419/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 420/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 421/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 422/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 423/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 424/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 425/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 426/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 427/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 428/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 429/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 430/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 431/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 432/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 433/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 434/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 435/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 436/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 437/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 438/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 439/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 440/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 441/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 442/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 443/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 444/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 445/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 446/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 447/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 448/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 449/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 450/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 451/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 452/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 453/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 454/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 455/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 456/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 457/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 458/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 459/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 460/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 461/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 462/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 463/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 464/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 465/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 466/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 467/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 468/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 469/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 470/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 471/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 472/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 473/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 474/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 475/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 476/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 477/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 478/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 479/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 480/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 481/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 482/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 483/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 484/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 485/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 486/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 487/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 488/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 489/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 490/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 491/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 492/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 493/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 494/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 495/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 496/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 497/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 498/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 499/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 500/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 501/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 502/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 503/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 504/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 505/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 506/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 507/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 508/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 509/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 510/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 511/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 512/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 513/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 514/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 515/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 516/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 517/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 518/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 519/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 520/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 521/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 522/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 523/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 524/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 525/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 526/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 527/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 528/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 529/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 530/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 531/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 532/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 533/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 534/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 535/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 536/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 537/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 538/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 539/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 540/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 541/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 542/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 543/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 544/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 545/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 546/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 547/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 548/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 549/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 550/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 551/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 552/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 553/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 554/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 555/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 556/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 557/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 558/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 559/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 560/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 561/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 562/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 563/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 564/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 565/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 566/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 567/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 568/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 569/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 570/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 571/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 572/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 573/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 574/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 575/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 576/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 577/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 578/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 579/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 580/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 581/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 582/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 583/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 584/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 585/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 586/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 587/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 588/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 589/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 590/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 591/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 592/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 593/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 594/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 595/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 596/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 597/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 598/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 599/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 600/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 601/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 602/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 603/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 604/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 605/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 606/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 607/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 608/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 609/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 610/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 611/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 612/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 613/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 614/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 615/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 616/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 617/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 618/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 619/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 620/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 621/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 622/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 623/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 624/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 625/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 626/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 627/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 628/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 629/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 630/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 631/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 632/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 633/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 634/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 635/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 636/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 637/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 638/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 639/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 640/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 641/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 642/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 643/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 644/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 645/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 646/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 647/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 648/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 649/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 650/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 651/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 652/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 653/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 654/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 655/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 656/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 657/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 658/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 659/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 660/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 661/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 662/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 663/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 664/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 665/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 666/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 667/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 668/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 669/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 670/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 671/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 672/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 673/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 674/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 675/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 676/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 677/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 678/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 679/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 680/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 681/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 682/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 683/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 684/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 685/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 686/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 687/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 688/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 689/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 690/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 691/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 692/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 693/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 694/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 695/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 696/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 697/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 698/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 699/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 700/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 701/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 702/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 703/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 704/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 705/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 706/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 707/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 708/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 709/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 710/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 711/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 712/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 713/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 714/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 715/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 716/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 717/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 718/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 719/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 720/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 721/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 722/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 723/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 724/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 725/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 726/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 727/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 728/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 729/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 730/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 731/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 732/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 733/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 734/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 735/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 736/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 737/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 738/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 739/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 740/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 741/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 742/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 743/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 744/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 745/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 746/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 747/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 748/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 749/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 750/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 751/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 752/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 753/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 754/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 755/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 756/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 757/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 758/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 759/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 760/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 761/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 762/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 763/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 764/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 765/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 766/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 767/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 768/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 769/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 770/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 771/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 772/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 773/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 774/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 775/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 776/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 777/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 778/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 779/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 780/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 781/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 782/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 783/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 784/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 785/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 786/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 787/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 788/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 789/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 790/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 791/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 792/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 793/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 794/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 795/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 796/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 797/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 798/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 799/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 800/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 801/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 802/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 803/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 804/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 805/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 806/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 807/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 808/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 809/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 810/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 811/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 812/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 813/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 814/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 815/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 816/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 817/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 818/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 819/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 820/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 821/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 822/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 823/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 824/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 825/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 826/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 827/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 828/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 829/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 830/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 831/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 832/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 833/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 834/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 835/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 836/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 837/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 838/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 839/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 840/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 841/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 842/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 843/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 844/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 845/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 846/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 847/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 848/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 849/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 850/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 851/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 852/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 853/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 854/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 855/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 856/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 857/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 858/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 859/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 860/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 861/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 862/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 863/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 864/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 865/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 866/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 867/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 868/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 869/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 870/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 871/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 872/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 873/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 874/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 875/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 876/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 877/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 878/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 879/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 880/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 881/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 882/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 883/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 884/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 885/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 886/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 887/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 888/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 889/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 890/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 891/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 892/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 893/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 894/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 895/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 896/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 897/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 898/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 899/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 900/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 901/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 902/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 903/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 904/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 905/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 906/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 907/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 908/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 909/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 910/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 911/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 912/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 913/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 914/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 915/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 916/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 917/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 918/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 919/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 920/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 921/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 922/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 923/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 924/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 925/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 926/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 927/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 928/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 929/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 930/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 931/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 932/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 933/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 934/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 935/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 936/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 937/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 938/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 939/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 940/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 941/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 942/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 943/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 944/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 945/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 946/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 947/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 948/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 949/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 950/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 951/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 952/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 953/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 954/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 955/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 956/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 957/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 958/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 959/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 960/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 961/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 962/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 963/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 964/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 965/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 966/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 967/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 968/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 969/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 970/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 971/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 972/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 973/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 974/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 975/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 976/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 977/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 978/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 979/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 980/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 981/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 982/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 983/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 984/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 985/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 986/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 987/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 988/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 989/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 990/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 991/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 992/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 993/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 994/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 995/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 996/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 997/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 998/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 999/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotting the training and validation accuracy\n",
        "plt.plot([i for i in range(len(train_accuracy_list))], train_accuracy_list, label=\"train\")\n",
        "plt.plot([i for i in range(len(validation_accuracy_list))], validation_accuracy_list, label='validation')\n",
        "plt.legend(loc=\"upper left\")\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 466
        },
        "id": "tWnM52i1V-JZ",
        "outputId": "4bfcc6fd-46a2-427f-e3b8-bcd8dd9cdb85"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'Accuracy')"
            ]
          },
          "metadata": {},
          "execution_count": 49
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "true_labels = []\n",
        "predicted_labels = []\n",
        "\n",
        "# Main training loop\n",
        "for epoch in range(epochs):\n",
        "    # Learning rate scheduling (optional)\n",
        "    if epoch % 500 == 0:\n",
        "        learning_rate *= .9\n",
        "\n",
        "    per_epoch_loss_list = []\n",
        "\n",
        "    for batch_idx, (X, Y) in enumerate(train_data_loader):\n",
        "        probs = model(X)\n",
        "\n",
        "        # new loss is the old loss + regularization term\n",
        "        loss = loss_fn(probs.view(-1), Y)\n",
        "\n",
        "        per_epoch_loss_list.append(loss.item())\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    with t.no_grad():\n",
        "        # Calculate accuracy on train data\n",
        "        model.eval()\n",
        "        probs = model(X_train_tensor)\n",
        "        prediction = (probs >= .5).type(t.LongTensor).view(-1)\n",
        "\n",
        "        train_accuracy = (prediction == Y_train_tensor).type(t.float32).mean().item()\n",
        "\n",
        "        # Collect true and predicted labels\n",
        "        true_labels.extend(Y_train)\n",
        "        predicted_labels.extend(prediction.numpy())\n",
        "\n",
        "        # Calculate accuracy on validation data\n",
        "        probs = model(X_test_tensor)\n",
        "        prediction = (probs > .5).type(t.LongTensor).view(-1)\n",
        "\n",
        "        validation_accuracy = (prediction == Y_test_tensor).type(t.float32).mean().item()\n",
        "\n",
        "        print(f'epoch {epoch}/{epochs} ---> train_accuracy : {train_accuracy} , validation_accuracy : {validation_accuracy}')\n",
        "        model.train()\n",
        "        train_accuracy_list.append(train_accuracy)\n",
        "        validation_accuracy_list.append(validation_accuracy)\n",
        "\n",
        "# Function to plot confusion matrix\n",
        "def plot_confusion_matrix(y_true, y_pred):\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    ax = plt.subplot()\n",
        "    sns.heatmap(cm, annot=True, ax=ax, fmt='g', cmap='Blues')  # annot=True to annotate cells, fmt='g' to disable scientific notation\n",
        "    ax.set_xlabel('Predicted labels')\n",
        "    ax.set_ylabel('True labels')\n",
        "    ax.set_title('Confusion Matrix')\n",
        "    ax.xaxis.set_ticklabels(['Negative', 'Positive'])\n",
        "    ax.yaxis.set_ticklabels(['Negative', 'Positive'])\n",
        "    plt.show()\n",
        "\n",
        "# Assuming you have collected the true and predicted labels during training\n",
        "plot_confusion_matrix(true_labels, predicted_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "5nOu6vTTWfqX",
        "outputId": "8ca45286-b082-4706-e1f7-10d59760ef03"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 1/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 2/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 3/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 4/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 5/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 6/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 7/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 8/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 9/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 10/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 11/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 12/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 13/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 14/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 15/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 16/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 17/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 18/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 19/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 20/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 21/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 22/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 23/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 24/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 25/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 26/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 27/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 28/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 29/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 30/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 31/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 32/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 33/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 34/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 35/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 36/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 37/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 38/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 39/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 40/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 41/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 42/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 43/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 44/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 45/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 46/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 47/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 48/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 49/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 50/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 51/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 52/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 53/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 54/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 55/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 56/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 57/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 58/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 59/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 60/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 61/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 62/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 63/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 64/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 65/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 66/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 67/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 68/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 69/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 70/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 71/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 72/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 73/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 74/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 75/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 76/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 77/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 78/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 79/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 80/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 81/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 82/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 83/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 84/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 85/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 86/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 87/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 88/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 89/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 90/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 91/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 92/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 93/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 94/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 95/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 96/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 97/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 98/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 99/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 100/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 101/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 102/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 103/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 104/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 105/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 106/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 107/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 108/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 109/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 110/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 111/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 112/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 113/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 114/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 115/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 116/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 117/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 118/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 119/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 120/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 121/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 122/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 123/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 124/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 125/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 126/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 127/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 128/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 129/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 130/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 131/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 132/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 133/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 134/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 135/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 136/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 137/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 138/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 139/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 140/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 141/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 142/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 143/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 144/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 145/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 146/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 147/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 148/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 149/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 150/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 151/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 152/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 153/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 154/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 155/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 156/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 157/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 158/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 159/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 160/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 161/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 162/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 163/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 164/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 165/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 166/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 167/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 168/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 169/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 170/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 171/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 172/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 173/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 174/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 175/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 176/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 177/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 178/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 179/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 180/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 181/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 182/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 183/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 184/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 185/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 186/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 187/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 188/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 189/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 190/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 191/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 192/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 193/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 194/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 195/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 196/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 197/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 198/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 199/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 200/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 201/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 202/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 203/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 204/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 205/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 206/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 207/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 208/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 209/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 210/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 211/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 212/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 213/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 214/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 215/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 216/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 217/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 218/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 219/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 220/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 221/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 222/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 223/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 224/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 225/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 226/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 227/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 228/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 229/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 230/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 231/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 232/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 233/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 234/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 235/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 236/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 237/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 238/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 239/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 240/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 241/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 242/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 243/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 244/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 245/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 246/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 247/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 248/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 249/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 250/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 251/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 252/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 253/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 254/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 255/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 256/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 257/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 258/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 259/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 260/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 261/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 262/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 263/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 264/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 265/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 266/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 267/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 268/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 269/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 270/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 271/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 272/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 273/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 274/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 275/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 276/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 277/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 278/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 279/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 280/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 281/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 282/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 283/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 284/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 285/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 286/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 287/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 288/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 289/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 290/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 291/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 292/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 293/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 294/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 295/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 296/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 297/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 298/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 299/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 300/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 301/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 302/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 303/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 304/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 305/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 306/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 307/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 308/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 309/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 310/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 311/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 312/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 313/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 314/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 315/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 316/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 317/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 318/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 319/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 320/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 321/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 322/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 323/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 324/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 325/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 326/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 327/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 328/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 329/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 330/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 331/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 332/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 333/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 334/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 335/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 336/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 337/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 338/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 339/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 340/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 341/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 342/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 343/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 344/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 345/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 346/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 347/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 348/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 349/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 350/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 351/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 352/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 353/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 354/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 355/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 356/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 357/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 358/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 359/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 360/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 361/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 362/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 363/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 364/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 365/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 366/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 367/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 368/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 369/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 370/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 371/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 372/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 373/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 374/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 375/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 376/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 377/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 378/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 379/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 380/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 381/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 382/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 383/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 384/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 385/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 386/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 387/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 388/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 389/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 390/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 391/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 392/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 393/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 394/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 395/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 396/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 397/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 398/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 399/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 400/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 401/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 402/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 403/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 404/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 405/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 406/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 407/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 408/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 409/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 410/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 411/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 412/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 413/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 414/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 415/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 416/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 417/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 418/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 419/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 420/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 421/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 422/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 423/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 424/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 425/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 426/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 427/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 428/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 429/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 430/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 431/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 432/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 433/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 434/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 435/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 436/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 437/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 438/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 439/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 440/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 441/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 442/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 443/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 444/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 445/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 446/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 447/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 448/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 449/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 450/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 451/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 452/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 453/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 454/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 455/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 456/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 457/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 458/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 459/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 460/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 461/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 462/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 463/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 464/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 465/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 466/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 467/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 468/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 469/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 470/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 471/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 472/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 473/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 474/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 475/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 476/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 477/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 478/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 479/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 480/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 481/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 482/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 483/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 484/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 485/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 486/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 487/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 488/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 489/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 490/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 491/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 492/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 493/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 494/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 495/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 496/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 497/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 498/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 499/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 500/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 501/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 502/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 503/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 504/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 505/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 506/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 507/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 508/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 509/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 510/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 511/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 512/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 513/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 514/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 515/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 516/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 517/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 518/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 519/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 520/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 521/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 522/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 523/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 524/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 525/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 526/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 527/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 528/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 529/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 530/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 531/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 532/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 533/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 534/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 535/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 536/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 537/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 538/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 539/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 540/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 541/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 542/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 543/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 544/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 545/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 546/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 547/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 548/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 549/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 550/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 551/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 552/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 553/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 554/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 555/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 556/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 557/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 558/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 559/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 560/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 561/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 562/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 563/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 564/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 565/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 566/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 567/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 568/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 569/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 570/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 571/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 572/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 573/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 574/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 575/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 576/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 577/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 578/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 579/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 580/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 581/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 582/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 583/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 584/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 585/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 586/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 587/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 588/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 589/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 590/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 591/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 592/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 593/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 594/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 595/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 596/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 597/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 598/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 599/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 600/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 601/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 602/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 603/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 604/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 605/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 606/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 607/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 608/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 609/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 610/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 611/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 612/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 613/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 614/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 615/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 616/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 617/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 618/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 619/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 620/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 621/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 622/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 623/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 624/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 625/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 626/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 627/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 628/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 629/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 630/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 631/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 632/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 633/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 634/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 635/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 636/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 637/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 638/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 639/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 640/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 641/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 642/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 643/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 644/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 645/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 646/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 647/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 648/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 649/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 650/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 651/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 652/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 653/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 654/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 655/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 656/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 657/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 658/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 659/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 660/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 661/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 662/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 663/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 664/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 665/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 666/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 667/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 668/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 669/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 670/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 671/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 672/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 673/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 674/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 675/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 676/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 677/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 678/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 679/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 680/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 681/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 682/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 683/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 684/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 685/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 686/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 687/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 688/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 689/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 690/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 691/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 692/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 693/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 694/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 695/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 696/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 697/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 698/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 699/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 700/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 701/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 702/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 703/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 704/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 705/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 706/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 707/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 708/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 709/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 710/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 711/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 712/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 713/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 714/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 715/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 716/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 717/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 718/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 719/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 720/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 721/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 722/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 723/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 724/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 725/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 726/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 727/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 728/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 729/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 730/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 731/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 732/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 733/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 734/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 735/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 736/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 737/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 738/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 739/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 740/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 741/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 742/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 743/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 744/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 745/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 746/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 747/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 748/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 749/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 750/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 751/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 752/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 753/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 754/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 755/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 756/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 757/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 758/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 759/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 760/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 761/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 762/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 763/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 764/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 765/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 766/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 767/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 768/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 769/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 770/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 771/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 772/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 773/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 774/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 775/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 776/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 777/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 778/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 779/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 780/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 781/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 782/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 783/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 784/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 785/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 786/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 787/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 788/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 789/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 790/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 791/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 792/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 793/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 794/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 795/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 796/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 797/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 798/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 799/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 800/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 801/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 802/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 803/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 804/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 805/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 806/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 807/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 808/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 809/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 810/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 811/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 812/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 813/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 814/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 815/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 816/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 817/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 818/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 819/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 820/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 821/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 822/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 823/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 824/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 825/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 826/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 827/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 828/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 829/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 830/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 831/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 832/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 833/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 834/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 835/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 836/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 837/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 838/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 839/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 840/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 841/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 842/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 843/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 844/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 845/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 846/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 847/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 848/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 849/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 850/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 851/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 852/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 853/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 854/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 855/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 856/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 857/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 858/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 859/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 860/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 861/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 862/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 863/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 864/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 865/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 866/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 867/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 868/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 869/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 870/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 871/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 872/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 873/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 874/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 875/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 876/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 877/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 878/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 879/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 880/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 881/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 882/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 883/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 884/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 885/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 886/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 887/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 888/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 889/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 890/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 891/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 892/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 893/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 894/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 895/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 896/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 897/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 898/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 899/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 900/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 901/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 902/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 903/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 904/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 905/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 906/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 907/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 908/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 909/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 910/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 911/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 912/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 913/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 914/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 915/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 916/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 917/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 918/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 919/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 920/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 921/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 922/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 923/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 924/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 925/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 926/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 927/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 928/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 929/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 930/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 931/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 932/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 933/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 934/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 935/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 936/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 937/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 938/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 939/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 940/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 941/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 942/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 943/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 944/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 945/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 946/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 947/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 948/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 949/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 950/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 951/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 952/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 953/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 954/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 955/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 956/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 957/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 958/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 959/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 960/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 961/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 962/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 963/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 964/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 965/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 966/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 967/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 968/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 969/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 970/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 971/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 972/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 973/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 974/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 975/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 976/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 977/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 978/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 979/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 980/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 981/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 982/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 983/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 984/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 985/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 986/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 987/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 988/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 989/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 990/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 991/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 992/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 993/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 994/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 995/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 996/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 997/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 998/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n",
            "epoch 999/1000 ---> train_accuracy : 0.9138304591178894 , validation_accuracy : 0.9133895635604858\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPQJ7+t5zvC4quJeEJaZQ19",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}